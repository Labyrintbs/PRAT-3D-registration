{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_landmarks(txt_path):\n",
    "    \"\"\"\n",
    "    Load landmark coordinates exported from CloudCompare.\n",
    "    Supports both CSV (x,y,z) and space-separated formats.\n",
    "    Returns: (N,3) numpy array\n",
    "    \"\"\"\n",
    "    pts = []\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if \",\" in line:\n",
    "                vals = line.split(\",\")\n",
    "            else:\n",
    "                vals = line.split()\n",
    "\n",
    "            if len(vals) < 3:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                x = float(vals[0])\n",
    "                y = float(vals[1])\n",
    "                z = float(vals[2])\n",
    "                pts.append([x, y, z])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return np.asarray(pts, dtype=np.float64)\n",
    "\n",
    "def compute_rigid_transform(P, Q):\n",
    "    \"\"\"\n",
    "    Given 2 list of points:\n",
    "      P: (N, 3) moving object points (mov_landmarks)\n",
    "      Q: (N, 3) reference object points (ref_landmarks)\n",
    "    Solve Rigid transformation T so that Q ≈ R @ P + t\n",
    "    Return:\n",
    "     4x4 transform matrix T\n",
    "    \"\"\"\n",
    "    assert P.shape == Q.shape\n",
    "    # Centroid\n",
    "    centroid_P = P.mean(axis=0)\n",
    "    centroid_Q = Q.mean(axis=0)\n",
    "\n",
    "    # Decentroid\n",
    "    P_centered = P - centroid_P\n",
    "    Q_centered = Q - centroid_Q\n",
    "\n",
    "    # Covariance\n",
    "    H = P_centered.T @ Q_centered\n",
    "\n",
    "    # SVD\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T @ U.T\n",
    "\n",
    "    # Reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "\n",
    "    # translation\n",
    "    t = centroid_Q - R @ centroid_P\n",
    "\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/nfs/Etu0/21400500/PRAT\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 1349372 points.\n",
      "PointCloud with 1711170 points.\n",
      "Landmark pairs: (5, 3)\n"
     ]
    }
   ],
   "source": [
    "ref_pcd_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_pcd_path = \"Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "ref_lm_path  = \"Data/ICP_test/picking_list_Tete_D.txt\"\n",
    "mov_lm_path  = \"Data/ICP_test/picking_list_Dragon_01_Transform.txt\"\n",
    "\n",
    "# Read Point Cloud\n",
    "ref_pcd = o3d.io.read_point_cloud(ref_pcd_path)\n",
    "mov_pcd_raw = o3d.io.read_point_cloud(mov_pcd_path)\n",
    "\n",
    "print(ref_pcd)\n",
    "print(mov_pcd_raw)\n",
    "\n",
    "# Read landmarks\n",
    "Q = load_landmarks(ref_lm_path)  # reference\n",
    "P = load_landmarks(mov_lm_path)  # moving\n",
    "\n",
    "print(\"Landmark pairs:\", P.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial transform (from landmarks):\n",
      " [[ 9.62467722e-01  2.70397248e-01 -2.32639644e-02 -3.62131506e+01]\n",
      " [-2.70754231e-01  9.50764689e-01 -1.50793408e-01 -8.51340723e+02]\n",
      " [-1.86555667e-02  1.51432605e-01  9.88291524e-01 -2.97968502e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_init = compute_rigid_transform(P, Q)\n",
    "print(\"Initial transform (from landmarks):\\n\", T_init)\n",
    "np.savetxt(\"T_landmark_4x4.txt\", T_init)\n",
    "\n",
    "\n",
    "# mov_pcd_landmark = mov_pcd.transform(T_init.copy())\n",
    "\n",
    "# o3d.io.write_point_cloud(\"../Data/ICP_test/dragon_after_landmark.ply\", mov_pcd_landmark)\n",
    "\n",
    "mov_after_landmark = copy.deepcopy(mov_pcd_raw)\n",
    "mov_after_landmark.transform(T_init)\n",
    "o3d.io.write_point_cloud(\"../Data/ICP_test/dragon_after_landmark.ply\", mov_after_landmark)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICP result:\n",
      "  fitness: 0.8167061133610337\n",
      "  inlier_rmse: 1.7607851593499075\n",
      "  T_icp:\n",
      " [[ 9.54561581e-01  2.96914653e-01 -2.55710273e-02 -4.80688633e+01]\n",
      " [-2.97020892e-01  9.40874457e-01 -1.62892129e-01 -9.31408116e+02]\n",
      " [-2.43059335e-02  1.63085697e-01  9.86312464e-01 -4.09150237e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "max_corr_dist = 10.0\n",
    "\n",
    "result_icp = o3d.pipelines.registration.registration_icp(\n",
    "    mov_pcd_raw,                   # source\n",
    "    ref_pcd,                       # target\n",
    "    max_corr_dist,\n",
    "    T_init,                        # init_trans from Landmark coarse registration\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(\n",
    "        max_iteration=100\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ICP result:\")\n",
    "print(\"  fitness:\", result_icp.fitness)\n",
    "print(\"  inlier_rmse:\", result_icp.inlier_rmse)\n",
    "print(\"  T_icp:\\n\", result_icp.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aligned point cloud to dragon_after_icp_python.ply\n",
      "Saved ICP transform to T_icp_4x4.txt\n"
     ]
    }
   ],
   "source": [
    "T_total = result_icp.transformation\n",
    "np.savetxt(\"T_icp_total_4x4.txt\", T_total)\n",
    "\n",
    "mov_after_icp = copy.deepcopy(mov_pcd_raw)\n",
    "mov_after_icp.transform(T_total)\n",
    "o3d.io.write_point_cloud(\"../Data/ICP_test/dragon_after_icp_python.ply\", mov_after_icp)\n",
    "\n",
    "\n",
    "print(\"Saved aligned point cloud to dragon_after_icp_python.ply\")\n",
    "print(\"Saved ICP transform to T_icp_4x4.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "Apply icp to mov dragon\n",
    "\n",
    "[11:24:13] [ComputeDistances] Mean distance = 11.4888 / std deviation = 26.862\n",
    "\n",
    "Default software algo:\n",
    "\n",
    "[11:58:09] [ComputeDistances] Mean distance = 11.5154 / std deviation = 26.9277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPFH + RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd: o3d.geometry.PointCloud, voxel_size):\n",
    "    \"\"\"\n",
    "    Downsample + normal estimation + FPFH feature extraction.\n",
    "\n",
    "    Returns:\n",
    "        pcd_down: downsampled point cloud with normals\n",
    "        fpfh:     o3d.pipelines.registration.Feature (shape: 33 x N)\n",
    "    \"\"\"\n",
    "    # Voxel downsample \n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # Remove statistical outliers\n",
    "    # Considered as outlier if avg dist among neighbors >= global avg dist + std_ratio * std\n",
    "    pcd_down, _ = pcd_down.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "\n",
    "    # Estimate normals\n",
    "    radius_normal = voxel_size * 2.0\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30)\n",
    "    )\n",
    "\n",
    "    # Compute FPFH feature\n",
    "    radius_feature = voxel_size * 5.0\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100)\n",
    "    )\n",
    "\n",
    "    return pcd_down, fpfh\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    \"\"\"Visualize alignment with two colors.\"\"\"\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1.0, 0.0, 0.0])  # red\n",
    "    target_temp.paint_uniform_color([0.0, 0.5, 1.0])  # blue\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def global_registration_ransac(src_down, tgt_down, src_fpfh, tgt_fpfh, voxel_size: float):\n",
    "    \"\"\"\n",
    "    RANSAC-based global registration on FPFH feature matches.\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        src_down, tgt_down,\n",
    "        src_fpfh, tgt_fpfh,\n",
    "        mutual_filter=True, # ensure src/tar NN corespondance\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False), # rigid transform\n",
    "        ransac_n=4, # sample point pairs to solve T \n",
    "        checkers=[ # pre filter\n",
    "            # Enforce similar edge length ratios to reject degenerate matches\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            # Reject matches with too large geometric distance\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold),\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(\n",
    "            max_iteration=100000,  \n",
    "            confidence=0.999\n",
    "        )\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def refine_registration_icp(src_full, tgt_full, init_T, voxel_size, use_point_to_plane=False):\n",
    "    \"\"\"\n",
    "    ICP refinement (point-to-plane is usually better if normals are reliable).\n",
    "    \"\"\"\n",
    "    # Set a tighter threshold than RANSAC\n",
    "    max_corr_dist = voxel_size * 1.0\n",
    "\n",
    "    if use_point_to_plane:\n",
    "        # Normals are required for point-to-plane ICP (target normals are used)\n",
    "        tgt_full.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30)\n",
    "        )\n",
    "        src_full.estimate_normals(\n",
    "            o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30)\n",
    "        )\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    else:\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "\n",
    "    result_icp = o3d.pipelines.registration.registration_icp(\n",
    "        src_full, tgt_full,\n",
    "        max_corr_dist,\n",
    "        init_T,\n",
    "        estimation_method=estimation,\n",
    "        criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=80)\n",
    "    )\n",
    "    return result_icp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  ref: PointCloud with 1349372 points.\n",
      "  mov: PointCloud with 1711170 points.\n",
      "Downsampled:\n",
      "  ref_down: PointCloud with 57450 points.\n",
      "  mov_down: PointCloud with 59566 points.\n",
      "FPFH dims: (33, 57450) (33, 59566)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "\n",
    "ref_pcd = o3d.io.read_point_cloud(ref_path)\n",
    "mov_pcd = o3d.io.read_point_cloud(mov_path)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\"  ref:\", ref_pcd)\n",
    "print(\"  mov:\", mov_pcd)\n",
    "\n",
    "\n",
    "voxel_size = 5.0\n",
    "\n",
    "# 1) Preprocess for FPFH + RANSAC on downsampled point clouds\n",
    "\n",
    "ref_down, ref_fpfh = preprocess_point_cloud(ref_pcd, voxel_size)\n",
    "mov_down, mov_fpfh = preprocess_point_cloud(mov_pcd, voxel_size)\n",
    "\n",
    "print(\"Downsampled:\")\n",
    "print(\"  ref_down:\", ref_down)\n",
    "print(\"  mov_down:\", mov_down)\n",
    "print(\"FPFH dims:\", ref_fpfh.data.shape, mov_fpfh.data.shape)  # (33, N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANSAC result:\n",
      "  fitness: 0.7834838666353289\n",
      "  inlier_rmse: 3.1019662912121815\n",
      "  T_ransac:\n",
      " [[ 9.54613548e-01  2.96343564e-01 -2.98909013e-02 -6.65329423e+01]\n",
      " [-2.97143072e-01  9.40652027e-01 -1.63950475e-01 -9.35053741e+02]\n",
      " [-2.04687311e-02  1.65391218e-01  9.86015606e-01 -3.79398026e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 2) Global registration (RANSAC)\n",
    "result_ransac = global_registration_ransac(mov_down, ref_down, mov_fpfh, ref_fpfh, voxel_size)\n",
    "print(\"\\nRANSAC result:\")\n",
    "print(\"  fitness:\", result_ransac.fitness)\n",
    "print(\"  inlier_rmse:\", result_ransac.inlier_rmse)\n",
    "print(\"  T_ransac:\\n\", result_ransac.transformation)\n",
    "\n",
    "# Visualize coarse alignment\n",
    "# draw_registration_result(mov_down, ref_down, result_ransac.transformation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICP result:\n",
      "  fitness: 0.7907022680388273\n",
      "  inlier_rmse: 1.2211446491094433\n",
      "  T_icp:\n",
      " [[ 9.54329399e-01  2.97668489e-01 -2.54728901e-02 -4.74876094e+01]\n",
      " [-2.97744994e-01  9.40625151e-01 -1.63009952e-01 -9.32482540e+02]\n",
      " [-2.45624851e-02  1.63149615e-01  9.86295538e-01 -4.11525250e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 3) ICP refinement on full-resolution clouds (or you can use downsampled first)\n",
    "result_icp = refine_registration_icp(mov_pcd, ref_pcd, result_ransac.transformation, voxel_size, use_point_to_plane=True)\n",
    "print(\"\\nICP result:\")\n",
    "print(\"  fitness:\", result_icp.fitness)\n",
    "print(\"  inlier_rmse:\", result_icp.inlier_rmse)\n",
    "print(\"  T_icp:\\n\", result_icp.transformation)\n",
    "\n",
    "# Visualize refined alignment\n",
    "#draw_registration_result(mov_pcd, ref_pcd, result_icp.transformation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: mov_aligned_by_fpfh_ransac_icp_p2p.ply\n"
     ]
    }
   ],
   "source": [
    "# 4) Save transformed moving point cloud (optional)\n",
    "mov_aligned = copy.deepcopy(mov_pcd)\n",
    "mov_aligned.transform(result_icp.transformation)\n",
    "o3d.io.write_point_cloud(\"../Data/FPFH/mov_aligned_by_fpfh_ransac_icp_p2p.ply\", mov_aligned)\n",
    "print(\"\\nSaved:\", \"mov_aligned_by_fpfh_ransac_icp_p2p.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with unity meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  ref: PointCloud with 1349372 points.\n",
      "  mov: PointCloud with 1711170 points.\n",
      "Downsampled:\n",
      "  ref_down: PointCloud with 57450 points.\n",
      "  mov_down: PointCloud with 59565 points.\n",
      "FPFH dims: (33, 57450) (33, 59565)\n",
      "\n",
      "RANSAC result:\n",
      "  fitness: 0.7834466549147989\n",
      "  inlier_rmse: 0.0028374658134148792\n",
      "  T_ransac:\n",
      " [[ 0.95450323  0.29707459 -0.02588963 -0.0492163 ]\n",
      " [-0.29721961  0.94073464 -0.16333655 -0.93242842]\n",
      " [-0.02416787  0.16360017  0.98623065 -0.03930241]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "init_T translation: [-0.0492163  -0.93242842 -0.03930241]\n",
      "ref_full diag: 1.331735633805758\n",
      "mov_full diag: 1.364668405400209\n",
      "ref_full center: [-0.70876686 -0.25534312 -4.61519417]\n",
      "mov_full center: [-0.71520521 -0.28435465 -4.60412256]\n",
      "\n",
      "ICP result:\n",
      "  fitness: 0.7907022680388273\n",
      "  inlier_rmse: 0.0012211446536510445\n",
      "  T_icp:\n",
      " [[ 0.95432939  0.29766852 -0.02547288 -0.04748758]\n",
      " [-0.29774502  0.94062514 -0.16300995 -0.93248253]\n",
      " [-0.02456249  0.16314961  0.98629554 -0.04115251]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "\n",
    "ref_pcd = o3d.io.read_point_cloud(ref_path)\n",
    "mov_pcd = o3d.io.read_point_cloud(mov_path)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\"  ref:\", ref_pcd)\n",
    "print(\"  mov:\", mov_pcd)\n",
    "\n",
    "\n",
    "voxel_size = 0.005\n",
    "\n",
    "\n",
    "ref_full, mov_full, ref_support, mov_support = prepare_clouds_scale_to_m(\n",
    "        ref_path, mov_path, 1e-3, 0.005)\n",
    "\n",
    "# 1) Preprocess for FPFH + RANSAC on downsampled point clouds\n",
    "\n",
    "ref_down, ref_fpfh = preprocess_point_cloud(ref_full, voxel_size)\n",
    "mov_down, mov_fpfh = preprocess_point_cloud(mov_full, voxel_size)\n",
    "\n",
    "print(\"Downsampled:\")\n",
    "print(\"  ref_down:\", ref_down)\n",
    "print(\"  mov_down:\", mov_down)\n",
    "print(\"FPFH dims:\", ref_fpfh.data.shape, mov_fpfh.data.shape)  # (33, N)\n",
    "\n",
    "# 2) Global registration (RANSAC)\n",
    "result_ransac = global_registration_ransac(mov_down, ref_down, mov_fpfh, ref_fpfh, voxel_size)\n",
    "print(\"\\nRANSAC result:\")\n",
    "print(\"  fitness:\", result_ransac.fitness)\n",
    "print(\"  inlier_rmse:\", result_ransac.inlier_rmse)\n",
    "print(\"  T_ransac:\\n\", result_ransac.transformation)\n",
    "\n",
    "print(\"init_T translation:\", result_ransac.transformation[:3,3])\n",
    "print(\"ref_full diag:\", np.linalg.norm(ref_full.get_axis_aligned_bounding_box().get_extent()))\n",
    "print(\"mov_full diag:\", np.linalg.norm(mov_full.get_axis_aligned_bounding_box().get_extent()))\n",
    "print(\"ref_full center:\", ref_full.get_center())\n",
    "print(\"mov_full center:\", mov_full.get_center())\n",
    "\n",
    "# 3) ICP refinement on full-resolution clouds (or you can use downsampled first)\n",
    "result_icp = refine_registration_icp(\n",
    "    mov_full, ref_full,\n",
    "    result_ransac.transformation,\n",
    "    voxel_size,\n",
    "    use_point_to_plane=True\n",
    ")\n",
    "print(\"\\nICP result:\")\n",
    "print(\"  fitness:\", result_icp.fitness)\n",
    "print(\"  inlier_rmse:\", result_icp.inlier_rmse)\n",
    "print(\"  T_icp:\\n\", result_icp.transformation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "[16:12:34] [ComputeDistances] Mean distance = 11.5045 / std deviation = 26.9021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nn_distances(source: o3d.geometry.PointCloud, target: o3d.geometry.PointCloud) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute nearest neighbor distances from each point in 'source' to 'target'.\n",
    "    Returns:\n",
    "        dists: (N,) array of Euclidean distances.\n",
    "    \"\"\"\n",
    "    target_kd = o3d.geometry.KDTreeFlann(target)\n",
    "    src_pts = np.asarray(source.points)\n",
    "\n",
    "    dists = np.empty(len(src_pts), dtype=np.float64)\n",
    "    for i, p in enumerate(src_pts):\n",
    "        # 1-NN search\n",
    "        _, idx, dist2 = target_kd.search_knn_vector_3d(p, 1)\n",
    "        dists[i] = np.sqrt(dist2[0])\n",
    "    return dists\n",
    "\n",
    "\n",
    "def registration_metrics(source_aligned: o3d.geometry.PointCloud,\n",
    "                         target: o3d.geometry.PointCloud,\n",
    "                         thresholds=(5.0, 10.0),\n",
    "                         percentiles=(50, 90, 95)) -> dict:\n",
    "    \"\"\"\n",
    "    Compute overlap-aware metrics for registration evaluation.\n",
    "\n",
    "    Metrics:\n",
    "      - median / P90 / P95 distances\n",
    "      - coverage@tau: ratio of points with dist < tau\n",
    "      - trimmed_rmse@tau: RMSE computed only on points with dist < tau\n",
    "      - mean / std (for reference)\n",
    "    \"\"\"\n",
    "    d = nn_distances(source_aligned, target)\n",
    "\n",
    "    out = {\n",
    "        \"mean\": float(d.mean()),\n",
    "        \"std\": float(d.std()),\n",
    "        \"median\": float(np.percentile(d, 50)),\n",
    "    }\n",
    "    for p in percentiles:\n",
    "        out[f\"p{p}\"] = float(np.percentile(d, p))\n",
    "\n",
    "    for tau in thresholds:\n",
    "        inliers = d < tau\n",
    "        coverage = float(inliers.mean())\n",
    "        if inliers.any():\n",
    "            trimmed_rmse = float(np.sqrt(np.mean(d[inliers] ** 2)))\n",
    "            trimmed_mean = float(d[inliers].mean())\n",
    "        else:\n",
    "            trimmed_rmse = float(\"nan\")\n",
    "            trimmed_mean = float(\"nan\")\n",
    "        out[f\"coverage@{tau}\"] = coverage\n",
    "        out[f\"trimmed_mean@{tau}\"] = trimmed_mean\n",
    "        out[f\"trimmed_rmse@{tau}\"] = trimmed_rmse\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def symmetric_chamfer(source_aligned: o3d.geometry.PointCloud,\n",
    "                      target: o3d.geometry.PointCloud) -> float:\n",
    "    \"\"\"\n",
    "    Symmetric Chamfer distance (mean NN distance both directions).\n",
    "    \"\"\"\n",
    "    d_st = nn_distances(source_aligned, target).mean()\n",
    "    d_ts = nn_distances(target, source_aligned).mean()\n",
    "    return float(d_st + d_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original not registered evaluation\n",
      "{'mean': 28.790589237437796, 'std': 21.611957785388448, 'median': 24.060411166186718, 'p50': 24.060411166186718, 'p90': 61.29547679266786, 'p95': 71.37153082536858, 'coverage@5.0': 0.1196292595124973, 'trimmed_mean@5.0': 2.4777668386423106, 'trimmed_rmse@5.0': 2.83796814333311, 'coverage@10.0': 0.22594189940216344, 'trimmed_mean@10.0': 4.844387508719292, 'trimmed_rmse@10.0': 5.637451842177725}\n",
      "Symmetric Chamfer: 54.16179091590028\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"../Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"../Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "src = o3d.io.read_point_cloud(mov_path)\n",
    "tgt = o3d.io.read_point_cloud(ref_path)\n",
    "\n",
    "# src_aligned = copy.deepcopy(src)\n",
    "# src_aligned.transform(T_total)\n",
    "\n",
    "metrics = registration_metrics(src, tgt, thresholds=(5.0, 10.0))\n",
    "print(\"Original not registered evaluation\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"Symmetric Chamfer:\", symmetric_chamfer(src, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual landmark + ICP evaluation\n",
      "{'mean': 11.900873394379946, 'std': 26.68532721206653, 'median': 0.8916812282821849, 'p50': 0.8916812282821849, 'p90': 52.385716913856236, 'p95': 79.81466731250123, 'coverage@5.0': 0.7907560324222608, 'trimmed_mean@5.0': 0.9568073840270434, 'trimmed_rmse@5.0': 1.224656404608553, 'coverage@10.0': 0.8167061133610337, 'trimmed_mean@10.0': 1.1507352380483076, 'trimmed_rmse@10.0': 1.7607851593499064}\n",
      "Symmetric Chamfer: 16.668003987122248\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"../Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"../Data/ICP_test/dragon_after_icp_python.ply\"\n",
    "src = o3d.io.read_point_cloud(mov_path)\n",
    "tgt = o3d.io.read_point_cloud(ref_path)\n",
    "\n",
    "# src_aligned = copy.deepcopy(src)\n",
    "# src_aligned.transform(T_total)\n",
    "\n",
    "metrics = registration_metrics(src, tgt, thresholds=(5.0, 10.0))\n",
    "print(\"Manual landmark + ICP evaluation\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"Symmetric Chamfer:\", symmetric_chamfer(src, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPFH + RANSAC + ICP evaluation\n",
      "{'mean': 11.919651183532961, 'std': 26.723596740054912, 'median': 0.8878449859671382, 'p50': 0.8878449859671382, 'p90': 52.503750839545056, 'p95': 79.93291604220614, 'coverage@5.0': 0.7907022680388273, 'trimmed_mean@5.0': 0.953115089069285, 'trimmed_rmse@5.0': 1.2211446515516156, 'coverage@10.0': 0.8165477421880936, 'trimmed_mean@10.0': 1.1466224471712876, 'trimmed_rmse@10.0': 1.7575508328904914}\n",
      "Symmetric Chamfer: 16.678766929614426\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"../Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"../Data/FPFH/mov_aligned_by_fpfh_ransac_icp_p2p.ply\"\n",
    "src = o3d.io.read_point_cloud(mov_path)\n",
    "tgt = o3d.io.read_point_cloud(ref_path)\n",
    "\n",
    "# src_aligned = copy.deepcopy(src)\n",
    "# src_aligned.transform(T_total)\n",
    "\n",
    "metrics = registration_metrics(src, tgt, thresholds=(5.0, 10.0))\n",
    "print(\"FPFH + RANSAC + ICP evaluation\")\n",
    "print(metrics)\n",
    "\n",
    "print(\"Symmetric Chamfer:\", symmetric_chamfer(src, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpinNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"./SpinNet\"))\n",
    "from network.SpinNet import Descriptor_Net\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "\n",
    "def load_ckpt_strip_module(ckpt_path: str, map_location=\"cpu\"):\n",
    "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
    "\n",
    "    # 情况1：直接就是 state_dict\n",
    "    state_dict = ckpt\n",
    "\n",
    "    # 情况2：ckpt 是 dict，里面有 'state_dict' 或 'model'\n",
    "    if isinstance(ckpt, dict):\n",
    "        if \"state_dict\" in ckpt:\n",
    "            state_dict = ckpt[\"state_dict\"]\n",
    "        elif \"model\" in ckpt:\n",
    "            state_dict = ckpt[\"model\"]\n",
    "        elif \"net\" in ckpt:\n",
    "            state_dict = ckpt[\"net\"]\n",
    "\n",
    "    # 去掉 'module.' 前缀\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_k = k[7:] if k.startswith(\"module.\") else k\n",
    "        new_state_dict[new_k] = v\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def build_spinnet_model(ckpt_path,\n",
    "                        des_r=0.30, rad_n=9, azi_n=80, ele_n=40,\n",
    "                        voxel_r=0.04, voxel_sample=30,\n",
    "                        dataset=\"3DMatch\",\n",
    "                        device=\"cuda:0\"):\n",
    "\n",
    "    model = Descriptor_Net(des_r, rad_n, azi_n, ele_n, voxel_r, voxel_sample, dataset)\n",
    "\n",
    "    sd = load_ckpt_strip_module(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "    # strict=True 一般就能过；如果你改过网络结构才需要 strict=False\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "def spinnet_features_for_pcd(pcd_down: o3d.geometry.PointCloud,\n",
    "                             model: torch.nn.Module,\n",
    "                             patch_radius: float,\n",
    "                             N: int = 2048,\n",
    "                             batch_size: int = 64,\n",
    "                             device: str = 'cuda:0'):\n",
    "    \"\"\"\n",
    "    For each point in pcd_down, build a local patch (N,3), run SpinNet, return Open3D Feature (32, num_pts).\n",
    "    \"\"\"\n",
    "    pts = np.asarray(pcd_down.points).astype(np.float32)\n",
    "    num_pts = pts.shape[0]\n",
    "\n",
    "    # KDTree for neighborhood query\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd_down)\n",
    "\n",
    "    desc_list = []\n",
    "    # Build patches in chunks\n",
    "    patches_buf = []\n",
    "    idx_buf = []\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        center = pts[i]\n",
    "\n",
    "        # radius search\n",
    "        _, idxs, _ = kdtree.search_radius_vector_3d(center, patch_radius)\n",
    "        if len(idxs) < 5:\n",
    "            # fallback: if neighborhood is too small, just repeat center\n",
    "            patch = np.repeat(center[None, :], N, axis=0)\n",
    "        else:\n",
    "            neigh = pts[np.asarray(idxs, dtype=np.int64)]\n",
    "\n",
    "            # sample to fixed N\n",
    "            if neigh.shape[0] >= N:\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=False)\n",
    "                patch = neigh[sel]\n",
    "            else:\n",
    "                # pad by resampling with replacement\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=True)\n",
    "                patch = neigh[sel]\n",
    "\n",
    "            # IMPORTANT: ensure the last point is the center (SpinNet uses input[:, -1, :] as center)\n",
    "            patch[-1] = center\n",
    "\n",
    "        patches_buf.append(patch)\n",
    "        idx_buf.append(i)\n",
    "\n",
    "        # run a batch\n",
    "        if len(patches_buf) == batch_size or i == num_pts - 1:\n",
    "            batch = torch.from_numpy(np.stack(patches_buf, axis=0)).to(device=device, dtype=torch.float32)  # (B,N,3)\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)                   # (B,32,1,1)\n",
    "                out = out.view(out.shape[0], -1)     # (B,32)\n",
    "                out = F.normalize(out, p=2, dim=1)   # (B,32)\n",
    "            desc_list.append(out.detach().cpu().numpy())\n",
    "            patches_buf = []\n",
    "            idx_buf = []\n",
    "\n",
    "    desc = np.concatenate(desc_list, axis=0)  # (num_pts, 32)\n",
    "\n",
    "    feat = o3d.pipelines.registration.Feature()\n",
    "    feat.data = desc.T  # Open3D expects (dim, num_pts)\n",
    "    return feat\n",
    "    \n",
    "def neighborhood_stats(pcd_down, radius, max_check=5000):\n",
    "    pts = np.asarray(pcd_down.points)\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd_down)\n",
    "    n = pts.shape[0]\n",
    "    idxs = np.random.choice(n, size=min(n, max_check), replace=False)\n",
    "\n",
    "    counts = []\n",
    "    t0 = time.time()\n",
    "    for i in idxs:\n",
    "        _, nn, _ = kdtree.search_radius_vector_3d(pts[i], radius)\n",
    "        counts.append(len(nn))\n",
    "    t = time.time() - t0\n",
    "    counts = np.array(counts)\n",
    "    print(f\"[radius={radius}] checked {len(idxs)} points in {t:.2f}s\")\n",
    "    print(\"  nn count: min / median / p90 / max =\",\n",
    "          counts.min(), np.median(counts), np.percentile(counts, 90), counts.max())\n",
    "    return counts\n",
    "\n",
    "def spinnet_features_for_pcd_profiled(\n",
    "    pcd_down: o3d.geometry.PointCloud,\n",
    "    model: torch.nn.Module,\n",
    "    patch_radius: float,\n",
    "    N: int = 2048,\n",
    "    batch_size: int = 64,\n",
    "    device: str = \"cuda:0\",\n",
    "    warmup_batches: int = 2,\n",
    "):\n",
    "    pts = np.asarray(pcd_down.points).astype(np.float32)\n",
    "    num_pts = pts.shape[0]\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd_down)\n",
    "\n",
    "    # timers\n",
    "    t_kdtree = 0.0\n",
    "    t_patch  = 0.0\n",
    "    t_stack  = 0.0\n",
    "    t_fwd    = 0.0\n",
    "\n",
    "    desc_list = []\n",
    "    patches_buf = []\n",
    "\n",
    "    # optional warmup (use first few points)\n",
    "    if \"cuda\" in device and torch.cuda.is_available():\n",
    "        for _ in range(warmup_batches):\n",
    "            # build a tiny dummy batch\n",
    "            B = min(batch_size, max(1, num_pts))\n",
    "            dummy = torch.randn(B, N, 3, device=device, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.synchronize()\n",
    "                _ = model(dummy)\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "    t_total0 = time.perf_counter()\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        center = pts[i]\n",
    "\n",
    "        # 1) KDTree radius search timing\n",
    "        t0 = time.perf_counter()\n",
    "        _, idxs, _ = kdtree.search_radius_vector_3d(center, patch_radius)\n",
    "        t_kdtree += time.perf_counter() - t0\n",
    "\n",
    "        # 2) Patch build timing (sampling/padding)\n",
    "        t0 = time.perf_counter()\n",
    "        if len(idxs) < 5:\n",
    "            patch = np.repeat(center[None, :], N, axis=0)\n",
    "        else:\n",
    "            neigh = pts[np.asarray(idxs, dtype=np.int64)]\n",
    "            if neigh.shape[0] >= N:\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=False)\n",
    "            else:\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=True)\n",
    "            patch = neigh[sel]\n",
    "            patch[-1] = center\n",
    "        t_patch += time.perf_counter() - t0\n",
    "\n",
    "        patches_buf.append(patch)\n",
    "\n",
    "        # 3) batch forward timing\n",
    "        if len(patches_buf) == batch_size or i == num_pts - 1:\n",
    "            t0 = time.perf_counter()\n",
    "            batch_np = np.stack(patches_buf, axis=0)   # (B,N,3)\n",
    "            t_stack += time.perf_counter() - t0\n",
    "\n",
    "            batch = torch.from_numpy(batch_np).to(device=device, dtype=torch.float32)\n",
    "\n",
    "            if \"cuda\" in device and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            t0 = time.perf_counter()\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)               # (B,32,1,1) or similar\n",
    "                out = out.view(out.shape[0], -1) # (B,32)\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "            if \"cuda\" in device and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            t_fwd += time.perf_counter() - t0\n",
    "\n",
    "            desc_list.append(out.detach().cpu().numpy())\n",
    "            patches_buf = []\n",
    "\n",
    "    t_total = time.perf_counter() - t_total0\n",
    "\n",
    "    desc = np.concatenate(desc_list, axis=0)  # (num_pts, 32)\n",
    "    feat = o3d.pipelines.registration.Feature()\n",
    "    feat.data = desc.T  # (32, num_pts)\n",
    "\n",
    "    profile = {\n",
    "        \"num_pts\": num_pts,\n",
    "        \"total_s\": t_total,\n",
    "        \"per_point_ms\": (t_total / max(1, num_pts)) * 1000.0,\n",
    "        \"kdtree_s\": t_kdtree,\n",
    "        \"patch_build_s\": t_patch,\n",
    "        \"stack_s\": t_stack,\n",
    "        \"forward_s\": t_fwd,\n",
    "        \"kdtree_ms_per_pt\": (t_kdtree / max(1, num_pts)) * 1000.0,\n",
    "        \"patch_ms_per_pt\": (t_patch / max(1, num_pts)) * 1000.0,\n",
    "        \"stack_ms_per_pt\": (t_stack / max(1, num_pts)) * 1000.0,\n",
    "        \"fwd_ms_per_pt\": (t_fwd / max(1, num_pts)) * 1000.0,\n",
    "    }\n",
    "    return feat, profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag = 1331.7356338057582\n",
      "After scale, diag = 1.3317356338051947\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "\n",
    "ref_pcd = o3d.io.read_point_cloud(ref_path)\n",
    "mov_pcd = o3d.io.read_point_cloud(mov_path)\n",
    "\n",
    "\n",
    "bbox = ref_pcd.get_axis_aligned_bounding_box()\n",
    "diag = np.linalg.norm(bbox.get_extent())\n",
    "print(\"diag =\", diag) # Verify the len unity\n",
    "\n",
    "# 0) Unity transfer\n",
    "scale = 1e-3\n",
    "ref_pcd.scale(scale, center=ref_pcd.get_center())\n",
    "mov_pcd.scale(scale, center=mov_pcd.get_center())\n",
    "\n",
    "# 1) downsample（unity：m）\n",
    "voxel_size = 0.005  # 5mm = 0.005m\n",
    "ref_down = ref_pcd.voxel_down_sample(voxel_size)\n",
    "mov_down = mov_pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "ref_down, _ = ref_down.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "mov_down, _ = mov_down.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "\n",
    "bbox = ref_pcd.get_axis_aligned_bounding_box()\n",
    "diag = np.linalg.norm(bbox.get_extent())\n",
    "print(\"After scale, diag =\", diag) # Verify the len unity\n",
    "\n",
    "print(\"ref_down points:\", np.asarray(ref_down.points).shape[0])\n",
    "print(\"mov_down points:\", np.asarray(mov_down.points).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4027753/2108995958.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "# 2) Build SpinNet model\n",
    "ckpt_path = \"SpinNet/pre-trained_models/3DMatch_best.pkl\"   \n",
    "model = build_spinnet_model(ckpt_path,\n",
    "                            des_r=0.30, rad_n=9, azi_n=80, ele_n=40,\n",
    "                            voxel_r=0.04, voxel_sample=30,\n",
    "                            dataset=\"3DMatch\",\n",
    "                            device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded \n",
      "  ref_down: PointCloud with 57451 points.\n",
      "  mov_down: PointCloud with 59565 points.\n",
      "[radius=0.3] checked 5000 points in 10.37s\n",
      "  nn count: min / median / p90 / max = 4800 24746.5 32293.500000000007 36282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([32898, 23067, 28527, ..., 32842, 23483, 26997])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.5)\n",
    "print(\"Loaded \")\n",
    "print(\"  ref_down:\", ref_down)\n",
    "print(\"  mov_down:\", mov_down)\n",
    "\n",
    "neighborhood_stats(ref_down, radius=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated total seconds on full ref_down: 212.8129515532977\n"
     ]
    }
   ],
   "source": [
    "# 2.5) Time test\n",
    "idx = np.random.choice(len(ref_down.points), 2000, replace=False)\n",
    "ref_sub = ref_down.select_by_index(idx)\n",
    "\n",
    "_, prof_sub = spinnet_features_for_pcd_profiled(\n",
    "    ref_sub, model, patch_radius=0.30, N=2048, batch_size=32, device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "est_total = prof_sub[\"per_point_ms\"] * len(ref_down.points) / 1000.0\n",
    "print(\"estimated total seconds on full ref_down:\", est_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_pts': 2000, 'total_s': 7.408502952195704, 'per_point_ms': 3.704251476097852, 'kdtree_s': 0.1374448137357831, 'patch_build_s': 0.21178276371210814, 'stack_s': 0.019267170690000057, 'forward_s': 7.004434240050614, 'kdtree_ms_per_pt': 0.06872240686789155, 'patch_ms_per_pt': 0.10589138185605407, 'stack_ms_per_pt': 0.009633585345000029, 'fwd_ms_per_pt': 3.502217120025307}\n"
     ]
    }
   ],
   "source": [
    "print(prof_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) SpinNet feature（patch_radius：m）\n",
    "ref_feat, ref_prof = spinnet_features_for_pcd_profiled(ref_down, model, patch_radius=0.30, N=2048, batch_size=48, device=\"cuda:0\")\n",
    "\n",
    "\n",
    "#ref_feat = spinnet_features_for_pcd(ref_down, model, patch_radius=0.30, N=2048, batch_size=48, device=\"cuda:0\")\n",
    "#mov_feat = spinnet_features_for_pcd(mov_down, model, patch_radius=0.30, N=2048, batch_size=48, device=\"cuda:0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_pts': 57451, 'total_s': 366.79874674696475, 'per_point_ms': 6.3845493855105175, 'kdtree_s': 116.37929208111018, 'patch_build_s': 55.9014504281804, 'stack_s': 0.3908678153529763, 'forward_s': 193.26412159670144, 'kdtree_ms_per_pt': 2.0257139489497167, 'patch_ms_per_pt': 0.9730283272385232, 'stack_ms_per_pt': 0.00680349890085423, 'fwd_ms_per_pt': 3.363981855784955}\n"
     ]
    }
   ],
   "source": [
    "print(ref_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_feat, mov_prof = spinnet_features_for_pcd_profiled(mov_down, model, patch_radius=0.30, N=2048, batch_size=48, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_pts': 59565, 'total_s': 353.89798430912197, 'per_point_ms': 5.941374705097322, 'kdtree_s': 107.84113709721714, 'patch_build_s': 52.47581277042627, 'stack_s': 0.3811010494828224, 'forward_s': 192.4380912426859, 'kdtree_ms_per_pt': 1.8104782522826683, 'patch_ms_per_pt': 0.8809840136057462, 'stack_ms_per_pt': 0.006398070166756021, 'fwd_ms_per_pt': 3.23072427168112}\n"
     ]
    }
   ],
   "source": [
    "print(mov_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (514) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "\n",
      "RANSAC result:\n",
      "  fitness: 0.6604213883992277\n",
      "  inlier_rmse: 0.004330643965148919\n",
      "  T_ransac:\n",
      " [[ 9.43375853e-01  3.31017676e-01 -2.16632845e-02 -3.96642037e+01]\n",
      " [-3.29924565e-01  9.29454455e-01 -1.65118739e-01 -9.87221529e+02]\n",
      " [-3.45221849e-02  1.62916281e-01  9.86035752e-01 -5.37294406e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 4) RANSAC \n",
    "result_ransac = global_registration_ransac(mov_down, ref_down, mov_feat, ref_feat, voxel_size)\n",
    "print(\"\\nRANSAC result:\")\n",
    "print(\"  fitness:\", result_ransac.fitness)\n",
    "print(\"  inlier_rmse:\", result_ransac.inlier_rmse)\n",
    "print(\"  T_ransac:\\n\", result_ransac.transformation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ICP result:\n",
      "  fitness: 0.7907040212252435\n",
      "  inlier_rmse: 0.0012213668000526324\n",
      "  T_icp:\n",
      " [[ 9.54331532e-01  2.97661486e-01 -2.54748046e-02 -5.88602838e+01]\n",
      " [-2.97738628e-01  9.40628721e-01 -1.63000974e-01 -9.51272785e+02]\n",
      " [-2.45567794e-02  1.63141803e-01  9.86296972e-01 -4.53309096e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 5) ICP\n",
    "result_icp = refine_registration_icp(mov_pcd, ref_pcd, result_ransac.transformation, voxel_size, use_point_to_plane=False)\n",
    "print(\"\\nICP result:\")\n",
    "print(\"  fitness:\", result_icp.fitness)\n",
    "print(\"  inlier_rmse:\", result_icp.inlier_rmse)\n",
    "print(\"  T_icp:\\n\", result_icp.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: mov_aligned_by_SpinNet_ransac_icp_p2p.ply\n"
     ]
    }
   ],
   "source": [
    "# 4) Save transformed moving point cloud (optional)\n",
    "mov_aligned = copy.deepcopy(mov_pcd)\n",
    "mov_aligned.transform(result_icp.transformation)\n",
    "o3d.io.write_point_cloud(\"Data/SpinNet/mov_aligned_by_SpinNet_ransac_icp_p2p.ply\", mov_aligned)\n",
    "print(\"\\nSaved:\", \"mov_aligned_by_SpinNet_ransac_icp_p2p.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_registration(pcd, scale=1e-3):\n",
    "    p = o3d.geometry.PointCloud(pcd)  \n",
    "    c = p.get_center()\n",
    "    p.scale(scale, center=c)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 0.011918822987517803, 'std': 0.026722915787976767, 'median': 0.0008861635487700434, 'p50': 0.0008861635487700434, 'p90': 0.05249955660834527, 'p95': 0.07992664360168701, 'coverage@0.005': 0.7907040212252435, 'trimmed_mean@0.005': 0.0009527310011387557, 'trimmed_rmse@0.005': 0.0012213667999690684, 'coverage@0.01': 0.8165454046062051, 'trimmed_mean@0.01': 0.0011462205703362967, 'trimmed_rmse@0.01': 0.0017576162087935656}\n",
      "Symmetric Chamfer: 0.016677589187423562\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"Data/SpinNet/mov_aligned_by_SpinNet_ransac_icp_p2p.ply\"\n",
    "\n",
    "\n",
    "src = o3d.io.read_point_cloud(mov_path)\n",
    "tgt = o3d.io.read_point_cloud(ref_path)\n",
    "\n",
    "tgt = preprocess_for_registration(tgt)\n",
    "\n",
    "metrics = registration_metrics(src, tgt, thresholds=(0.005, 0.010))\n",
    "print(metrics)\n",
    "print(\"Symmetric Chamfer:\", symmetric_chamfer(src, tgt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SpinNet\n",
    "load training files ../../data/3DMatch/patches/train/train_anc&pos_20_2048_2000.pkl\n",
    "Epoch 19: Loss 1.0435524266898795, time 10648.4401s\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_4000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_6000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_8000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_10000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_12000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_14000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_16000.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_17043.pkl\n",
    "load training files ../../data/3DMatch/patches/val/val_anc&pos_2_2048_2000.pkl\n",
    "Evaluation: Epoch 19: Loss 1.2269546277540968\n",
    "Avg one epoch time: 10514.17, total 20 epochs time: 214677.52\n",
    "Training finish!... save training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare FPFH + ICP vs SpinNet + ICP on different downsample keypoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def now():\n",
    "    return time.perf_counter()\n",
    "\n",
    "def diag(pcd: o3d.geometry.PointCloud) -> float:\n",
    "    return float(np.linalg.norm(pcd.get_axis_aligned_bounding_box().get_extent()))\n",
    "\n",
    "def select_keypoints_random(pcd: o3d.geometry.PointCloud, K: int, seed: int = 0):\n",
    "    pts = np.asarray(pcd.points)\n",
    "    n = pts.shape[0]\n",
    "    if K >= n:\n",
    "        idx = np.arange(n, dtype=np.int64)\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(n, size=K, replace=False).astype(np.int64)\n",
    "\n",
    "    idx.sort()  # align with o3d order\n",
    "    kp = pcd.select_by_index(idx.tolist())\n",
    "    return kp, idx\n",
    "\n",
    "\n",
    "\n",
    "def compute_fpfh_for_support(pcd_support: o3d.geometry.PointCloud, voxel_size: float):\n",
    "    \"\"\"\n",
    "    Compute FPFH on a SUPPORT cloud (already downsampled + outlier-removed).\n",
    "    Returns:\n",
    "        fpfh: o3d.pipelines.registration.Feature (33, N_support)\n",
    "    \"\"\"\n",
    "    # Normals\n",
    "    radius_normal = voxel_size * 2.0\n",
    "    pcd_support.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30)\n",
    "    )\n",
    "\n",
    "    # FPFH\n",
    "    radius_feature = voxel_size * 5.0\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_support,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100)\n",
    "    )\n",
    "    return fpfh\n",
    "\n",
    "def slice_feature_by_index(feat: o3d.pipelines.registration.Feature, idx: np.ndarray):\n",
    "    \"\"\"\n",
    "    feat.data shape: (dim, N). Returns a Feature with shape (dim, K).\n",
    "    \"\"\"\n",
    "    f = o3d.pipelines.registration.Feature()\n",
    "    f.data = feat.data[:, idx]\n",
    "    return f\n",
    "\n",
    "\n",
    "def spinnet_features_for_keypoints_profiled(\n",
    "    support_pcd: o3d.geometry.PointCloud,   # KDTree & neighbor source\n",
    "    query_pcd: o3d.geometry.PointCloud,     # centers to compute descriptors (K points)\n",
    "    model: torch.nn.Module,\n",
    "    patch_radius: float,\n",
    "    N: int = 2048,\n",
    "    batch_size: int = 64,\n",
    "    device: str = \"cuda:0\",\n",
    "    warmup_batches: int = 2,\n",
    "):\n",
    "    support_pts = np.asarray(support_pcd.points).astype(np.float32)\n",
    "    query_pts   = np.asarray(query_pcd.points).astype(np.float32)\n",
    "    num_q = query_pts.shape[0]\n",
    "\n",
    "    kdtree = o3d.geometry.KDTreeFlann(support_pcd)\n",
    "\n",
    "    # timers\n",
    "    t_kdtree = 0.0\n",
    "    t_patch  = 0.0\n",
    "    t_stack  = 0.0\n",
    "    t_fwd    = 0.0\n",
    "\n",
    "    desc_list = []\n",
    "    patches_buf = []\n",
    "\n",
    "    # Model sanity check\n",
    "    if \"cuda\" in device and torch.cuda.is_available():\n",
    "        for _ in range(warmup_batches):\n",
    "            B = min(batch_size, max(1, num_q))\n",
    "            dummy = torch.randn(B, N, 3, device=device, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                torch.cuda.synchronize()\n",
    "                _ = model(dummy)\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "    t_total0 = time.perf_counter()\n",
    "\n",
    "    for i in range(num_q):\n",
    "        center = query_pts[i]\n",
    "\n",
    "        # 1) KDTree radius search on SUPPORT\n",
    "        t0 = time.perf_counter()\n",
    "        _, idxs, _ = kdtree.search_radius_vector_3d(center, patch_radius)\n",
    "        t_kdtree += time.perf_counter() - t0\n",
    "\n",
    "        # 2) Patch build from SUPPORT points, but force last point = QUERY center\n",
    "        t0 = time.perf_counter()\n",
    "        if len(idxs) < 5:\n",
    "            patch = np.repeat(center[None, :], N, axis=0)\n",
    "        else:\n",
    "            neigh = support_pts[np.asarray(idxs, dtype=np.int64)]\n",
    "            if neigh.shape[0] >= N:\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=False)\n",
    "            else:\n",
    "                sel = np.random.choice(neigh.shape[0], N, replace=True)\n",
    "            patch = neigh[sel]\n",
    "            patch[-1] = center\n",
    "        t_patch += time.perf_counter() - t0\n",
    "\n",
    "        patches_buf.append(patch)\n",
    "\n",
    "        # 3) batch forward\n",
    "        if len(patches_buf) == batch_size or i == num_q - 1:\n",
    "            t0 = time.perf_counter()\n",
    "            batch_np = np.stack(patches_buf, axis=0)\n",
    "            t_stack += time.perf_counter() - t0\n",
    "\n",
    "            batch = torch.from_numpy(batch_np).to(device=device, dtype=torch.float32)\n",
    "\n",
    "            if \"cuda\" in device and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            t0 = time.perf_counter()\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)\n",
    "                out = out.view(out.shape[0], -1)\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "            if \"cuda\" in device and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            t_fwd += time.perf_counter() - t0\n",
    "\n",
    "            desc_list.append(out.detach().cpu().numpy())\n",
    "            patches_buf = []\n",
    "\n",
    "    t_total = time.perf_counter() - t_total0\n",
    "\n",
    "    desc = np.concatenate(desc_list, axis=0)  # (K, 32)\n",
    "    feat = o3d.pipelines.registration.Feature()\n",
    "    feat.data = desc.T  # (32, K)\n",
    "\n",
    "    profile = {\n",
    "        \"num_query\": int(num_q),\n",
    "        \"total_s\": float(t_total),\n",
    "        \"per_query_ms\": float((t_total / max(1, num_q)) * 1000.0),\n",
    "        \"kdtree_s\": float(t_kdtree),\n",
    "        \"patch_build_s\": float(t_patch),\n",
    "        \"stack_s\": float(t_stack),\n",
    "        \"forward_s\": float(t_fwd),\n",
    "        \"kdtree_ms_per_q\": float((t_kdtree / max(1, num_q)) * 1000.0),\n",
    "        \"patch_ms_per_q\": float((t_patch / max(1, num_q)) * 1000.0),\n",
    "        \"stack_ms_per_q\": float((t_stack / max(1, num_q)) * 1000.0),\n",
    "        \"fwd_ms_per_q\": float((t_fwd / max(1, num_q)) * 1000.0),\n",
    "    }\n",
    "    return feat, profile\n",
    "\n",
    "def prepare_clouds_scale_to_m(\n",
    "    ref_path: str,\n",
    "    mov_path: str,\n",
    "    scale_to_m: float = 1e-3,\n",
    "    voxel_size: float = 0.005,\n",
    "    outlier_nb: int = 20,\n",
    "    outlier_std: float = 2.0,\n",
    "):\n",
    "    ref_raw = o3d.io.read_point_cloud(ref_path)\n",
    "    mov_raw = o3d.io.read_point_cloud(mov_path)\n",
    "\n",
    "    ref_full = copy.deepcopy(ref_raw)\n",
    "    mov_full = copy.deepcopy(mov_raw)\n",
    "\n",
    "    # TRUE unit conversion: scale around origin\n",
    "    ref_full.scale(scale_to_m, center=(0.0, 0.0, 0.0))\n",
    "    mov_full.scale(scale_to_m, center=(0.0, 0.0, 0.0))\n",
    "\n",
    "    # support clouds in meters\n",
    "    ref_support = ref_full.voxel_down_sample(voxel_size)\n",
    "    mov_support = mov_full.voxel_down_sample(voxel_size)\n",
    "\n",
    "    ref_support, _ = ref_support.remove_statistical_outlier(nb_neighbors=outlier_nb, std_ratio=outlier_std)\n",
    "    mov_support, _ = mov_support.remove_statistical_outlier(nb_neighbors=outlier_nb, std_ratio=outlier_std)\n",
    "\n",
    "    return ref_full, mov_full, ref_support, mov_support\n",
    "\n",
    "def save_aligned_cloud(\n",
    "    pcd: o3d.geometry.PointCloud,\n",
    "    base_dir: str,\n",
    "    K: int,\n",
    "    seed: int,\n",
    "    method: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save aligned point cloud to:\n",
    "    base_dir/K_<K>/seed_<seed>/mov_aligned_<method>.ply\n",
    "    \"\"\"\n",
    "    save_dir = os.path.join(base_dir, f\"K_{K}\", f\"seed_{seed}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    filename = f\"mov_aligned_{method}.ply\"\n",
    "    path = os.path.join(save_dir, filename)\n",
    "\n",
    "    o3d.io.write_point_cloud(path, pcd)\n",
    "    print(f\"[Saved] {path}\")\n",
    "\n",
    "    return path\n",
    "\n",
    "def assert_kp_alignment(support_pcd, kp_pcd, idx, name, tol=1e-12, n_check=20):\n",
    "    sup = np.asarray(support_pcd.points)\n",
    "    kp  = np.asarray(kp_pcd.points)\n",
    "    idx = np.asarray(idx, dtype=np.int64)\n",
    "\n",
    "    assert kp.shape[0] == idx.shape[0], f\"{name}: kp_n != idx_n\"\n",
    "    m = min(n_check, kp.shape[0])\n",
    "    for j in range(m):\n",
    "        d = np.linalg.norm(kp[j] - sup[idx[j]])\n",
    "        assert d < tol, f\"{name}: order mismatch at j={j}, ||kp-sup[idx]||={d}\"\n",
    "\n",
    "\n",
    "\n",
    "def run_one_K_seed_compare_fpfh_spinnet(\n",
    "    ref_full: o3d.geometry.PointCloud,\n",
    "    mov_full: o3d.geometry.PointCloud,\n",
    "    ref_support: o3d.geometry.PointCloud,\n",
    "    mov_support: o3d.geometry.PointCloud,\n",
    "    model: torch.nn.Module,\n",
    "    voxel_size: float,\n",
    "    patch_radius: float,\n",
    "    K: int,\n",
    "    seed: int,\n",
    "    N_patch: int = 2048,\n",
    "    batch_size: int = 48,\n",
    "    device: str = \"cuda:0\",\n",
    "    use_point_to_plane: bool = True,\n",
    "    eval_thresholds_m=(0.005, 0.010),\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict with:\n",
    "      - keypoint info\n",
    "      - timing breakdown for both methods\n",
    "      - RANSAC/ICP metrics and your evaluation metrics\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"K\": int(K),\n",
    "        \"seed\": int(seed),\n",
    "        \"voxel_size\": float(voxel_size),\n",
    "        \"patch_radius\": float(patch_radius),\n",
    "    }\n",
    "\n",
    "    # --- Keypoints, same idx for both methods ---\n",
    "    ref_kp, idx_ref = select_keypoints_random(ref_support, K, seed=seed)\n",
    "    mov_kp, idx_mov = select_keypoints_random(mov_support, K, seed=seed)\n",
    "\n",
    "    out[\"ref_support_n\"] = int(len(ref_support.points))\n",
    "    out[\"mov_support_n\"] = int(len(mov_support.points))\n",
    "    out[\"ref_kp_n\"] = int(len(ref_kp.points))\n",
    "    out[\"mov_kp_n\"] = int(len(mov_kp.points))\n",
    "\n",
    "    # ============================================================\n",
    "    # Method 1: FPFH (support full -> slice K)\n",
    "    # ============================================================\n",
    "    t0 = now()\n",
    "    ref_fpfh_all = compute_fpfh_for_support(ref_support, voxel_size)\n",
    "    mov_fpfh_all = compute_fpfh_for_support(mov_support, voxel_size)\n",
    "    t_fpfh_feat = now() - t0\n",
    "\n",
    "    ref_fpfh_kp = slice_feature_by_index(ref_fpfh_all, idx_ref)\n",
    "    mov_fpfh_kp = slice_feature_by_index(mov_fpfh_all, idx_mov)\n",
    "    \n",
    "    assert_kp_alignment(ref_support, ref_kp, idx_ref, \"ref\")\n",
    "    assert_kp_alignment(mov_support, mov_kp, idx_mov, \"mov\")\n",
    "    # RANSAC\n",
    "    t0 = now()\n",
    "    ransac_fpfh = global_registration_ransac(mov_kp, ref_kp, mov_fpfh_kp, ref_fpfh_kp, voxel_size)\n",
    "    t_fpfh_ransac = now() - t0\n",
    "\n",
    "    # ICP\n",
    "    t0 = now()\n",
    "    icp_fpfh = refine_registration_icp(mov_full, ref_full, ransac_fpfh.transformation, voxel_size, use_point_to_plane=use_point_to_plane)\n",
    "    t_fpfh_icp = now() - t0\n",
    "\n",
    "    # Evaluate\n",
    "    mov_aligned_fpfh = copy.deepcopy(mov_full)\n",
    "    mov_aligned_fpfh.transform(icp_fpfh.transformation)\n",
    "\n",
    "    eval_fpfh = registration_metrics(mov_aligned_fpfh, ref_full, thresholds=eval_thresholds_m)\n",
    "    chamfer_fpfh = symmetric_chamfer(mov_aligned_fpfh, ref_full)\n",
    "\n",
    "    out.update({\n",
    "        \"fpfh_feat_s\": float(t_fpfh_feat),\n",
    "        \"fpfh_ransac_s\": float(t_fpfh_ransac),\n",
    "        \"fpfh_icp_s\": float(t_fpfh_icp),\n",
    "        \"fpfh_total_s\": float(t_fpfh_feat + t_fpfh_ransac + t_fpfh_icp),\n",
    "\n",
    "        \"fpfh_ransac_fitness\": float(ransac_fpfh.fitness),\n",
    "        \"fpfh_ransac_rmse\": float(ransac_fpfh.inlier_rmse),\n",
    "        \"fpfh_icp_fitness\": float(icp_fpfh.fitness),\n",
    "        \"fpfh_icp_rmse\": float(icp_fpfh.inlier_rmse),\n",
    "\n",
    "        \"fpfh_cov_5mm\": float(eval_fpfh.get(f\"coverage@{eval_thresholds_m[0]}\", np.nan)),\n",
    "        \"fpfh_cov_10mm\": float(eval_fpfh.get(f\"coverage@{eval_thresholds_m[1]}\", np.nan)),\n",
    "        \"fpfh_trimrmse_5mm\": float(eval_fpfh.get(f\"trimmed_rmse@{eval_thresholds_m[0]}\", np.nan)),\n",
    "        \"fpfh_trimrmse_10mm\": float(eval_fpfh.get(f\"trimmed_rmse@{eval_thresholds_m[1]}\", np.nan)),\n",
    "        \"fpfh_chamfer\": float(chamfer_fpfh),\n",
    "    })\n",
    "\n",
    "    # ============================================================\n",
    "    # Method 2: SpinNet (support/query separated)\n",
    "    # ============================================================\n",
    "    # Feature extraction (profile already contains time)\n",
    "    sp_ref_feat, sp_ref_prof = spinnet_features_for_keypoints_profiled(\n",
    "        support_pcd=ref_support,\n",
    "        query_pcd=ref_kp,\n",
    "        model=model,\n",
    "        patch_radius=patch_radius,\n",
    "        N=N_patch,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "    )\n",
    "    sp_mov_feat, sp_mov_prof = spinnet_features_for_keypoints_profiled(\n",
    "        support_pcd=mov_support,\n",
    "        query_pcd=mov_kp,\n",
    "        model=model,\n",
    "        patch_radius=patch_radius,\n",
    "        N=N_patch,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    t_sp_feat = sp_ref_prof[\"total_s\"] + sp_mov_prof[\"total_s\"]\n",
    "\n",
    "    # RANSAC\n",
    "    t0 = now()\n",
    "    ransac_sp = global_registration_ransac(mov_kp, ref_kp, sp_mov_feat, sp_ref_feat, voxel_size)\n",
    "    t_sp_ransac = now() - t0\n",
    "\n",
    "    # ICP\n",
    "    t0 = now()\n",
    "    icp_sp = refine_registration_icp(mov_full, ref_full, ransac_sp.transformation, voxel_size, use_point_to_plane=use_point_to_plane)\n",
    "    t_sp_icp = now() - t0\n",
    "\n",
    "    # Evaluate\n",
    "    mov_aligned_sp = copy.deepcopy(mov_full)\n",
    "    mov_aligned_sp.transform(icp_sp.transformation)\n",
    "\n",
    "    eval_sp = registration_metrics(mov_aligned_sp, ref_full, thresholds=eval_thresholds_m)\n",
    "    chamfer_sp = symmetric_chamfer(mov_aligned_sp, ref_full)\n",
    "\n",
    "    out.update({\n",
    "        \"spinnet_ref_feat_s\": float(sp_ref_prof[\"total_s\"]),\n",
    "        \"spinnet_mov_feat_s\": float(sp_mov_prof[\"total_s\"]),\n",
    "        \"spinnet_feat_s\": float(t_sp_feat),\n",
    "        \"spinnet_ransac_s\": float(t_sp_ransac),\n",
    "        \"spinnet_icp_s\": float(t_sp_icp),\n",
    "        \"spinnet_total_s\": float(t_sp_feat + t_sp_ransac + t_sp_icp),\n",
    "\n",
    "        \"spinnet_ransac_fitness\": float(ransac_sp.fitness),\n",
    "        \"spinnet_ransac_rmse\": float(ransac_sp.inlier_rmse),\n",
    "        \"spinnet_icp_fitness\": float(icp_sp.fitness),\n",
    "        \"spinnet_icp_rmse\": float(icp_sp.inlier_rmse),\n",
    "\n",
    "        \"spinnet_cov_5mm\": float(eval_sp.get(f\"coverage@{eval_thresholds_m[0]}\", np.nan)),\n",
    "        \"spinnet_cov_10mm\": float(eval_sp.get(f\"coverage@{eval_thresholds_m[1]}\", np.nan)),\n",
    "        \"spinnet_trimrmse_5mm\": float(eval_sp.get(f\"trimmed_rmse@{eval_thresholds_m[0]}\", np.nan)),\n",
    "        \"spinnet_trimrmse_10mm\": float(eval_sp.get(f\"trimmed_rmse@{eval_thresholds_m[1]}\", np.nan)),\n",
    "        \"spinnet_chamfer\": float(chamfer_sp),\n",
    "    })\n",
    "\n",
    "    out[\"fpfh_T_icp\"] = icp_fpfh.transformation\n",
    "    out[\"spinnet_T_icp\"] = icp_sp.transformation\n",
    "\n",
    "\n",
    "    # Save all results:\n",
    "    save_base = \"Data/Registrations\"\n",
    "\n",
    "    save_aligned_cloud(\n",
    "    pcd=mov_aligned_fpfh,\n",
    "    base_dir=save_base,\n",
    "    K=K,\n",
    "    seed=seed,\n",
    "    method=\"FPFH\",\n",
    "    )\n",
    "\n",
    "    save_aligned_cloud(\n",
    "    pcd=mov_aligned_sp,\n",
    "    base_dir=save_base,\n",
    "    K=K,\n",
    "    seed=seed,\n",
    "    method=\"SpinNet\",\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def save_out_json(out: dict, base_dir: str, K: int, seed: int):\n",
    "    \"\"\"\n",
    "    Save the full `out` dict to:\n",
    "    base_dir/K_<K>/seed_<seed>/out.json\n",
    "    \"\"\"\n",
    "    save_dir = os.path.join(base_dir, f\"K_{K}\", f\"seed_{seed}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    path = os.path.join(save_dir, \"out.json\")\n",
    "\n",
    "    # numpy -> python float/int \n",
    "    def convert(o):\n",
    "        if hasattr(o, \"tolist\"):\n",
    "            return o.tolist()\n",
    "        return o\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(out, f, indent=2, default=convert)\n",
    "\n",
    "    print(f\"[Saved] {path}\")\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sweep(\n",
    "    ref_path: str,\n",
    "    mov_path: str,\n",
    "    model: torch.nn.Module,\n",
    "    Ks=(512, 1024, 2048, 4096, 8192, 16384, 32768),\n",
    "    seeds=(0, 1, 2),\n",
    "    scale_to_m: float = 1e-3,\n",
    "    voxel_size: float = 0.005,\n",
    "    patch_radius: float = 0.30,\n",
    "    N_patch: int = 2048,\n",
    "    batch_size: int = 96,\n",
    "    device: str = \"cuda:0\",\n",
    "    use_point_to_plane: bool = True,\n",
    "    eval_thresholds_m=(0.005, 0.010),\n",
    "):\n",
    "    # Prepare clouds once (shared by all runs)\n",
    "    ref_full, mov_full, ref_support, mov_support = prepare_clouds_scale_to_m(\n",
    "        ref_path, mov_path, scale_to_m=scale_to_m, voxel_size=voxel_size\n",
    "    )\n",
    "\n",
    "    print(\"Prepared:\")\n",
    "    print(\"  ref_full diag:\", diag(ref_full), \"center:\", ref_full.get_center())\n",
    "    print(\"  mov_full diag:\", diag(mov_full), \"center:\", mov_full.get_center())\n",
    "    print(\"  ref_support n:\", len(ref_support.points))\n",
    "    print(\"  mov_support n:\", len(mov_support.points))\n",
    "\n",
    "    results = []\n",
    "    for K in Ks:\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n=== Run K={K}, seed={seed} ===\")\n",
    "            out = run_one_K_seed_compare_fpfh_spinnet(\n",
    "                ref_full=ref_full,\n",
    "                mov_full=mov_full,\n",
    "                ref_support=ref_support,\n",
    "                mov_support=mov_support,\n",
    "                model=model,\n",
    "                voxel_size=voxel_size,\n",
    "                patch_radius=patch_radius,\n",
    "                K=K,\n",
    "                seed=seed,\n",
    "                N_patch=N_patch,\n",
    "                batch_size=batch_size,\n",
    "                device=device,\n",
    "                use_point_to_plane=use_point_to_plane,\n",
    "                eval_thresholds_m=eval_thresholds_m,\n",
    "            )\n",
    "            save_out_json(out=out, base_dir=\"Data/Registrations\", K=K, seed=seed,)\n",
    "            results.append(out)\n",
    "            print(\"  FPFH total_s:\", out[\"fpfh_total_s\"], \"cov@5mm:\", out[\"fpfh_cov_5mm\"], \"rmse@5mm:\", out[\"fpfh_trimrmse_5mm\"])\n",
    "            print(\"  Spin total_s:\", out[\"spinnet_total_s\"], \"cov@5mm:\", out[\"spinnet_cov_5mm\"], \"rmse@5mm:\", out[\"spinnet_trimrmse_5mm\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared:\n",
      "  ref_full diag: 1.331735633805758 center: [-0.70876686 -0.25534312 -4.61519417]\n",
      "  mov_full diag: 1.364668405400209 center: [-0.71520521 -0.28435465 -4.60412256]\n",
      "  ref_support n: 57450\n",
      "  mov_support n: 59565\n",
      "\n",
      "=== Run K=512, seed=0 ===\n",
      "[Saved] Data/Registrations/K_512/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_512/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_512/seed_0/out.json\n",
      "  FPFH total_s: 7.6443045837804675 cov@5mm: 0.7907016836433551 rmse@5mm: 0.0012211375524111196\n",
      "  Spin total_s: 12.858805415220559 cov@5mm: 0.7907016836433551 rmse@5mm: 0.00122113757617147\n",
      "\n",
      "=== Run K=512, seed=1 ===\n",
      "[Saved] Data/Registrations/K_512/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_512/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_512/seed_1/out.json\n",
      "  FPFH total_s: 31.15536557789892 cov@5mm: 0.14580199512614175 rmse@5mm: 0.002839405135798507\n",
      "  Spin total_s: 15.11713317129761 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446531864662\n",
      "\n",
      "=== Run K=512, seed=2 ===\n",
      "[Saved] Data/Registrations/K_512/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_512/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_512/seed_2/out.json\n",
      "  FPFH total_s: 32.65379486884922 cov@5mm: 0.14580199512614175 rmse@5mm: 0.0028394051357985054\n",
      "  Spin total_s: 17.216748683713377 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446627713434\n",
      "\n",
      "=== Run K=1024, seed=0 ===\n",
      "[Saved] Data/Registrations/K_1024/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_0/out.json\n",
      "  FPFH total_s: 50.73594607412815 cov@5mm: 0.05263357819503615 rmse@5mm: 0.0028170629727069327\n",
      "  Spin total_s: 22.480565486475825 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446545708927\n",
      "\n",
      "=== Run K=1024, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (93) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_1024/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_1/out.json\n",
      "  FPFH total_s: 32.64724306110293 cov@5mm: 0.14580199512614175 rmse@5mm: 0.0028394051357985054\n",
      "  Spin total_s: 59.67425033915788 cov@5mm: 0.09296446291134136 rmse@5mm: 0.0028601474779613332\n",
      "\n",
      "=== Run K=1024, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (99) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_1024/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_1024/seed_2/out.json\n",
      "  FPFH total_s: 8.543849418871105 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446538493433\n",
      "  Spin total_s: 20.111177917569876 cov@5mm: 0.7907022680388273 rmse@5mm: 0.001221144654335926\n",
      "\n",
      "=== Run K=2048, seed=0 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (128) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_2048/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_0/out.json\n",
      "  FPFH total_s: 6.604436104185879 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446551635228\n",
      "  Spin total_s: 31.906249823980033 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446529887117\n",
      "\n",
      "=== Run K=2048, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (129) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_2048/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_1/out.json\n",
      "  FPFH total_s: 32.04213406238705 cov@5mm: 0.14580199512614175 rmse@5mm: 0.002839405135798501\n",
      "  Spin total_s: 52.14692339673638 cov@5mm: 0.7907022680388273 rmse@5mm: 0.001221144651789444\n",
      "\n",
      "=== Run K=2048, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (132) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_2048/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_2048/seed_2/out.json\n",
      "  FPFH total_s: 6.463402176275849 cov@5mm: 0.7907022680388273 rmse@5mm: 0.001221144654345515\n",
      "  Spin total_s: 45.351609352976084 cov@5mm: 0.7907028524342994 rmse@5mm: 0.0012211516117306258\n",
      "\n",
      "=== Run K=4096, seed=0 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (194) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_4096/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_0/out.json\n",
      "  FPFH total_s: 6.424063613638282 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446603477224\n",
      "  Spin total_s: 73.636643900536 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446507060903\n",
      "\n",
      "=== Run K=4096, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (187) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_4096/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_1/out.json\n",
      "  FPFH total_s: 5.506102814339101 cov@5mm: 0.7907028524342994 rmse@5mm: 0.0012211510550166448\n",
      "  Spin total_s: 72.96545632462949 cov@5mm: 0.7907016836433551 rmse@5mm: 0.0012211375238373955\n",
      "\n",
      "=== Run K=4096, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (193) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_4096/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_4096/seed_2/out.json\n",
      "  FPFH total_s: 7.000545863062143 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446507554198\n",
      "  Spin total_s: 72.96395978424698 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446553141404\n",
      "\n",
      "=== Run K=8192, seed=0 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (248) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_8192/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_0/out.json\n",
      "  FPFH total_s: 6.941900625824928 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446545224729\n",
      "  Spin total_s: 140.36757658794522 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446540268283\n",
      "\n",
      "=== Run K=8192, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (251) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_8192/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_1/out.json\n",
      "  FPFH total_s: 8.071858554147184 cov@5mm: 0.7907022680388273 rmse@5mm: 0.001221144654333737\n",
      "  Spin total_s: 139.6190902274102 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446544050414\n",
      "\n",
      "=== Run K=8192, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (253) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_8192/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_8192/seed_2/out.json\n",
      "  FPFH total_s: 6.424440389499068 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211445494263178\n",
      "  Spin total_s: 138.04180194623768 cov@5mm: 0.7907028524342994 rmse@5mm: 0.0012211516935522525\n",
      "\n",
      "=== Run K=16384, seed=0 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (314) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_16384/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_0/out.json\n",
      "  FPFH total_s: 8.77138404455036 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446548232646\n",
      "  Spin total_s: 216.60395623836666 cov@5mm: 0.7907028524342994 rmse@5mm: 0.001221151818149293\n",
      "\n",
      "=== Run K=16384, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (334) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_16384/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_1/out.json\n",
      "  FPFH total_s: 7.032321593724191 cov@5mm: 0.7907016836433551 rmse@5mm: 0.0012211384370608654\n",
      "  Spin total_s: 214.01731521170586 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446543750316\n",
      "\n",
      "=== Run K=16384, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (326) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_16384/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_16384/seed_2/out.json\n",
      "  FPFH total_s: 8.0034120362252 cov@5mm: 0.7907022680388273 rmse@5mm: 0.001221144655617176\n",
      "  Spin total_s: 213.90279569290578 cov@5mm: 0.7907028524342994 rmse@5mm: 0.0012211517087621806\n",
      "\n",
      "=== Run K=32768, seed=0 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (418) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_32768/seed_0/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_0/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_0/out.json\n",
      "  FPFH total_s: 12.983403923921287 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211452592968\n",
      "  Spin total_s: 439.44200614467263 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446632282483\n",
      "\n",
      "=== Run K=32768, seed=1 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (430) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_32768/seed_1/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_1/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_1/out.json\n",
      "  FPFH total_s: 13.927291155792773 cov@5mm: 0.7907028524342994 rmse@5mm: 0.001221151761613937\n",
      "  Spin total_s: 435.11244123149663 cov@5mm: 0.7907022680388273 rmse@5mm: 0.00122114465471699\n",
      "\n",
      "=== Run K=32768, seed=2 ===\n",
      "\u001b[1;33m[Open3D WARNING] Too few correspondences (407) after mutual filter, fall back to original correspondences.\u001b[0;m\n",
      "[Saved] Data/Registrations/K_32768/seed_2/mov_aligned_FPFH.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_2/mov_aligned_SpinNet.ply\n",
      "[Saved] Data/Registrations/K_32768/seed_2/out.json\n",
      "  FPFH total_s: 13.182791225612164 cov@5mm: 0.7907022680388273 rmse@5mm: 0.0012211446540562282\n",
      "  Spin total_s: 435.57560216262937 cov@5mm: 0.7907016836433551 rmse@5mm: 0.0012211375467751078\n"
     ]
    }
   ],
   "source": [
    "ref_path = \"Data/ICP_test/ref_Tete_D.ply\"\n",
    "mov_path = \"Data/ICP_test/move_Dragon_01_Transform.ply\"\n",
    "results = run_sweep(ref_path, mov_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'K': 512, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 512, 'mov_kp_n': 512, 'fpfh_feat_s': 0.3970149103552103, 'fpfh_ransac_s': 0.1712689409032464, 'fpfh_icp_s': 7.076020732522011, 'fpfh_total_s': 7.6443045837804675, 'fpfh_ransac_fitness': 0.048828125, 'fpfh_ransac_rmse': 0.005740113929802985, 'fpfh_icp_fitness': 0.7907016836433551, 'fpfh_icp_rmse': 0.0012211375524111333, 'fpfh_cov_5mm': 0.7907016836433551, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211375524111196, 'fpfh_trimrmse_10mm': 0.001757551096756306, 'fpfh_chamfer': 0.0166787665260775, 'spinnet_ref_feat_s': 3.0425073839724064, 'spinnet_mov_feat_s': 3.0006922790780663, 'spinnet_feat_s': 6.043199663050473, 'spinnet_ransac_s': 0.17391147557646036, 'spinnet_icp_s': 6.6416942765936255, 'spinnet_total_s': 12.858805415220559, 'spinnet_ransac_fitness': 0.052734375, 'spinnet_ransac_rmse': 0.005421764131669186, 'spinnet_icp_fitness': 0.7907016836433551, 'spinnet_icp_rmse': 0.0012211375761714733, 'spinnet_cov_5mm': 0.7907016836433551, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.00122113757617147, 'spinnet_trimrmse_10mm': 0.0017575512803195735, 'spinnet_chamfer': 0.01667876683854025, 'fpfh_T_icp': array([[ 0.95432941,  0.29766845, -0.0254728 , -0.04748714],\n",
      "       [-0.29774494,  0.94062517, -0.16300991, -0.93248232],\n",
      "       [-0.02456256,  0.16314955,  0.98629555, -0.04115258],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432938,  0.29766854, -0.02547285, -0.04748737],\n",
      "       [-0.29774504,  0.94062513, -0.16300998, -0.93248267],\n",
      "       [-0.02456254,  0.16314962,  0.98629553, -0.04115264],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 512, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 512, 'mov_kp_n': 512, 'fpfh_feat_s': 0.389222564175725, 'fpfh_ransac_s': 0.15521818306297064, 'fpfh_icp_s': 30.610924830660224, 'fpfh_total_s': 31.15536557789892, 'fpfh_ransac_fitness': 0.0, 'fpfh_ransac_rmse': 0.0, 'fpfh_icp_fitness': 0.14580199512614175, 'fpfh_icp_rmse': 0.0028394051357984998, 'fpfh_cov_5mm': 0.14580199512614175, 'fpfh_cov_10mm': 0.27648158862065136, 'fpfh_trimrmse_5mm': 0.002839405135798507, 'fpfh_trimrmse_10mm': 0.005640408268149719, 'fpfh_chamfer': 0.045561665531596116, 'spinnet_ref_feat_s': 4.374105745926499, 'spinnet_mov_feat_s': 3.886676580645144, 'spinnet_feat_s': 8.260782326571643, 'spinnet_ransac_s': 0.10488544218242168, 'spinnet_icp_s': 6.751465402543545, 'spinnet_total_s': 15.11713317129761, 'spinnet_ransac_fitness': 0.072265625, 'spinnet_ransac_rmse': 0.005647347865356667, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446531864522, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446531864662, 'spinnet_trimrmse_10mm': 0.0017575507954750039, 'spinnet_chamfer': 0.01667876592095671, 'fpfh_T_icp': array([[ 0.99871026,  0.04895088,  0.01347664,  0.07903875],\n",
      "       [-0.04819595,  0.9975057 , -0.0515706 , -0.26042766],\n",
      "       [-0.01596745,  0.05085457,  0.99857842, -0.00504563],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432941,  0.29766845, -0.02547284, -0.04748737],\n",
      "       [-0.29774495,  0.94062516, -0.16300995, -0.93248251],\n",
      "       [-0.02456253,  0.1631496 ,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 512, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 512, 'mov_kp_n': 512, 'fpfh_feat_s': 0.41751579102128744, 'fpfh_ransac_s': 0.1604612646624446, 'fpfh_icp_s': 32.075817813165486, 'fpfh_total_s': 32.65379486884922, 'fpfh_ransac_fitness': 0.0, 'fpfh_ransac_rmse': 0.0, 'fpfh_icp_fitness': 0.14580199512614175, 'fpfh_icp_rmse': 0.002839405135798513, 'fpfh_cov_5mm': 0.14580199512614175, 'fpfh_cov_10mm': 0.27648158862065136, 'fpfh_trimrmse_5mm': 0.0028394051357985054, 'fpfh_trimrmse_10mm': 0.005640408268149746, 'fpfh_chamfer': 0.045561665531596025, 'spinnet_ref_feat_s': 4.740759374573827, 'spinnet_mov_feat_s': 3.8233609665185213, 'spinnet_feat_s': 8.564120341092348, 'spinnet_ransac_s': 0.16518694162368774, 'spinnet_icp_s': 8.48744140099734, 'spinnet_total_s': 17.216748683713377, 'spinnet_ransac_fitness': 0.0390625, 'spinnet_ransac_rmse': 0.006041488387008965, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446627713556, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446627713434, 'spinnet_trimrmse_10mm': 0.001757551298368678, 'spinnet_chamfer': 0.016678769578371958, 'fpfh_T_icp': array([[ 0.99871026,  0.04895088,  0.01347664,  0.07903875],\n",
      "       [-0.04819595,  0.9975057 , -0.0515706 , -0.26042766],\n",
      "       [-0.01596745,  0.05085457,  0.99857842, -0.00504563],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432939,  0.29766852, -0.02547283, -0.04748733],\n",
      "       [-0.29774502,  0.94062515, -0.16300994, -0.93248249],\n",
      "       [-0.02456254,  0.16314958,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 1024, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 1024, 'mov_kp_n': 1024, 'fpfh_feat_s': 0.4278603522107005, 'fpfh_ransac_s': 0.16642267256975174, 'fpfh_icp_s': 50.1416630493477, 'fpfh_total_s': 50.73594607412815, 'fpfh_ransac_fitness': 0.009765625, 'fpfh_ransac_rmse': 0.005783909250845738, 'fpfh_icp_fitness': 0.05263357819503615, 'fpfh_icp_rmse': 0.002817062972706941, 'fpfh_cov_5mm': 0.05263357819503615, 'fpfh_cov_10mm': 0.09499289959501393, 'fpfh_trimrmse_5mm': 0.0028170629727069327, 'fpfh_trimrmse_10mm': 0.0054662640202860786, 'fpfh_chamfer': 0.17500868348110435, 'spinnet_ref_feat_s': 8.33760729804635, 'spinnet_mov_feat_s': 7.827789196744561, 'spinnet_feat_s': 16.16539649479091, 'spinnet_ransac_s': 0.11172669939696789, 'spinnet_icp_s': 6.203442292287946, 'spinnet_total_s': 22.480565486475825, 'spinnet_ransac_fitness': 0.12109375, 'spinnet_ransac_rmse': 0.005180252719445013, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.001221144654570905, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446545708927, 'spinnet_trimrmse_10mm': 0.0017575508335797452, 'spinnet_chamfer': 0.01667876608620484, 'fpfh_T_icp': array([[ 0.35432477, -0.70556322,  0.61370555,  2.07902779],\n",
      "       [-0.74595016, -0.60903246, -0.26951407, -2.22985835],\n",
      "       [ 0.56392581, -0.36229824, -0.74211028, -7.91497787],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432941,  0.29766847, -0.02547285, -0.04748741],\n",
      "       [-0.29774497,  0.94062516, -0.16300996, -0.93248255],\n",
      "       [-0.02456252,  0.16314961,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 1024, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 1024, 'mov_kp_n': 1024, 'fpfh_feat_s': 0.43965685088187456, 'fpfh_ransac_s': 0.19182564225047827, 'fpfh_icp_s': 32.015760567970574, 'fpfh_total_s': 32.64724306110293, 'fpfh_ransac_fitness': 0.0, 'fpfh_ransac_rmse': 0.0, 'fpfh_icp_fitness': 0.14580199512614175, 'fpfh_icp_rmse': 0.0028394051357984963, 'fpfh_cov_5mm': 0.14580199512614175, 'fpfh_cov_10mm': 0.27648158862065136, 'fpfh_trimrmse_5mm': 0.0028394051357985054, 'fpfh_trimrmse_10mm': 0.005640408268149703, 'fpfh_chamfer': 0.04556166553159599, 'spinnet_ref_feat_s': 7.744922775775194, 'spinnet_mov_feat_s': 6.727904049679637, 'spinnet_feat_s': 14.472826825454831, 'spinnet_ransac_s': 0.18864445853978395, 'spinnet_icp_s': 45.012779055163264, 'spinnet_total_s': 59.67425033915788, 'spinnet_ransac_fitness': 0.0126953125, 'spinnet_ransac_rmse': 0.00507439203015324, 'spinnet_icp_fitness': 0.09296446291134136, 'spinnet_icp_rmse': 0.002860147477961332, 'spinnet_cov_5mm': 0.09296446291134136, 'spinnet_cov_10mm': 0.1735397418140804, 'spinnet_trimrmse_5mm': 0.0028601474779613332, 'spinnet_trimrmse_10mm': 0.005588719582262548, 'spinnet_chamfer': 0.09148280217007927, 'fpfh_T_icp': array([[ 0.99871026,  0.04895088,  0.01347664,  0.07903875],\n",
      "       [-0.04819595,  0.9975057 , -0.0515706 , -0.26042766],\n",
      "       [-0.01596745,  0.05085457,  0.99857842, -0.00504563],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.63723901,  0.76983183, -0.03585235, -0.24530444],\n",
      "       [-0.74553444,  0.60400739, -0.2816975 , -1.94257024],\n",
      "       [-0.19520462,  0.2062378 ,  0.95883321, -0.30470654],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 1024, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 1024, 'mov_kp_n': 1024, 'fpfh_feat_s': 0.3977620480582118, 'fpfh_ransac_s': 0.16521315835416317, 'fpfh_icp_s': 7.98087421245873, 'fpfh_total_s': 8.543849418871105, 'fpfh_ransac_fitness': 0.0458984375, 'fpfh_ransac_rmse': 0.00563153696286472, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.001221144653849357, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446538493433, 'fpfh_trimrmse_10mm': 0.0017575508272631415, 'fpfh_chamfer': 0.016678766042740982, 'spinnet_ref_feat_s': 6.093963951803744, 'spinnet_mov_feat_s': 6.630200515501201, 'spinnet_feat_s': 12.724164467304945, 'spinnet_ransac_s': 0.2012112643569708, 'spinnet_icp_s': 7.18580218590796, 'spinnet_total_s': 20.111177917569876, 'spinnet_ransac_fitness': 0.06640625, 'spinnet_ransac_rmse': 0.00536511250507281, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.001221144654335926, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.001221144654335926, 'spinnet_trimrmse_10mm': 0.001757550796123976, 'spinnet_chamfer': 0.01667876587631231, 'fpfh_T_icp': array([[ 0.95432941,  0.29766847, -0.02547285, -0.04748741],\n",
      "       [-0.29774497,  0.94062516, -0.16300996, -0.93248255],\n",
      "       [-0.02456252,  0.16314961,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.9543294 ,  0.29766848, -0.02547286, -0.04748746],\n",
      "       [-0.29774498,  0.94062515, -0.16300997, -0.93248261],\n",
      "       [-0.02456252,  0.16314962,  0.98629554, -0.04115257],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 2048, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 2048, 'mov_kp_n': 2048, 'fpfh_feat_s': 0.41591550409793854, 'fpfh_ransac_s': 0.2139969142153859, 'fpfh_icp_s': 5.974523685872555, 'fpfh_total_s': 6.604436104185879, 'fpfh_ransac_fitness': 0.19189453125, 'fpfh_ransac_rmse': 0.005505989040923297, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446551635267, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446551635228, 'fpfh_trimrmse_10mm': 0.0017575511275105136, 'fpfh_chamfer': 0.016678767972211437, 'spinnet_ref_feat_s': 12.877625136636198, 'spinnet_mov_feat_s': 12.008532191626728, 'spinnet_feat_s': 24.886157328262925, 'spinnet_ransac_s': 0.34341345075517893, 'spinnet_icp_s': 6.676679044961929, 'spinnet_total_s': 31.906249823980033, 'spinnet_ransac_fitness': 0.15576171875, 'spinnet_ransac_rmse': 0.005617548875516759, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.001221144652988705, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446529887117, 'spinnet_trimrmse_10mm': 0.001757550965261545, 'spinnet_chamfer': 0.016678768846719663, 'fpfh_T_icp': array([[ 0.95432937,  0.29766858, -0.02547289, -0.04748761],\n",
      "       [-0.29774508,  0.94062512, -0.16300996, -0.93248266],\n",
      "       [-0.0245625 ,  0.16314962,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432939,  0.29766853, -0.02547293, -0.04748781],\n",
      "       [-0.29774504,  0.94062514, -0.16300993, -0.93248248],\n",
      "       [-0.02456245,  0.16314961,  0.98629554, -0.04115248],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 2048, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 2048, 'mov_kp_n': 2048, 'fpfh_feat_s': 0.43348339200019836, 'fpfh_ransac_s': 0.20964948274195194, 'fpfh_icp_s': 31.3990011876449, 'fpfh_total_s': 32.04213406238705, 'fpfh_ransac_fitness': 0.0, 'fpfh_ransac_rmse': 0.0, 'fpfh_icp_fitness': 0.14580199512614175, 'fpfh_icp_rmse': 0.0028394051357984937, 'fpfh_cov_5mm': 0.14580199512614175, 'fpfh_cov_10mm': 0.27648158862065136, 'fpfh_trimrmse_5mm': 0.002839405135798501, 'fpfh_trimrmse_10mm': 0.005640408268149728, 'fpfh_chamfer': 0.045561665531595956, 'spinnet_ref_feat_s': 15.428360609337687, 'spinnet_mov_feat_s': 16.739974873140454, 'spinnet_feat_s': 32.16833548247814, 'spinnet_ransac_s': 0.29816520493477583, 'spinnet_icp_s': 19.680422709323466, 'spinnet_total_s': 52.14692339673638, 'spinnet_ransac_fitness': 0.06640625, 'spinnet_ransac_rmse': 0.0057556950465365506, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446517894386, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.001221144651789444, 'spinnet_trimrmse_10mm': 0.0017575508545157666, 'spinnet_chamfer': 0.016678766943349712, 'fpfh_T_icp': array([[ 0.99871026,  0.04895088,  0.01347664,  0.07903875],\n",
      "       [-0.04819595,  0.9975057 , -0.0515706 , -0.26042766],\n",
      "       [-0.01596745,  0.05085457,  0.99857842, -0.00504563],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.9543294 ,  0.2976685 , -0.02547288, -0.04748758],\n",
      "       [-0.297745  ,  0.94062515, -0.16300995, -0.93248255],\n",
      "       [-0.02456249,  0.16314961,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 2048, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 2048, 'mov_kp_n': 2048, 'fpfh_feat_s': 0.4020287850871682, 'fpfh_ransac_s': 0.19698613323271275, 'fpfh_icp_s': 5.864387257955968, 'fpfh_total_s': 6.463402176275849, 'fpfh_ransac_fitness': 0.22802734375, 'fpfh_ransac_rmse': 0.005447444902400534, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446543455135, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.001221144654345515, 'fpfh_trimrmse_10mm': 0.0017575510855070374, 'fpfh_chamfer': 0.01667876680162487, 'spinnet_ref_feat_s': 16.611479826271534, 'spinnet_mov_feat_s': 15.703599907457829, 'spinnet_feat_s': 32.31507973372936, 'spinnet_ransac_s': 0.29564710799604654, 'spinnet_icp_s': 12.740882511250675, 'spinnet_total_s': 45.351609352976084, 'spinnet_ransac_fitness': 0.06298828125, 'spinnet_ransac_rmse': 0.005698548800654103, 'spinnet_icp_fitness': 0.7907028524342994, 'spinnet_icp_rmse': 0.001221151611730621, 'spinnet_cov_5mm': 0.7907028524342994, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211516117306258, 'spinnet_trimrmse_10mm': 0.0017575483883290062, 'spinnet_chamfer': 0.016678755766356385, 'fpfh_T_icp': array([[ 0.95432937,  0.29766857, -0.02547286, -0.04748747],\n",
      "       [-0.29774507,  0.94062512, -0.16300999, -0.93248279],\n",
      "       [-0.02456254,  0.16314964,  0.98629553, -0.04115257],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432938,  0.29766851, -0.02547317, -0.04748905],\n",
      "       [-0.29774506,  0.94062511, -0.16301009, -0.93248331],\n",
      "       [-0.02456226,  0.16314983,  0.98629551, -0.04115229],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 4096, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 4096, 'mov_kp_n': 4096, 'fpfh_feat_s': 0.4148030672222376, 'fpfh_ransac_s': 0.2900570323690772, 'fpfh_icp_s': 5.719203514046967, 'fpfh_total_s': 6.424063613638282, 'fpfh_ransac_fitness': 0.374755859375, 'fpfh_ransac_rmse': 0.005233459736159626, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446603477168, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446603477224, 'fpfh_trimrmse_10mm': 0.0017575512944559173, 'fpfh_chamfer': 0.016678770127598875, 'spinnet_ref_feat_s': 32.35963839944452, 'spinnet_mov_feat_s': 32.26257825829089, 'spinnet_feat_s': 64.62221665773541, 'spinnet_ransac_s': 1.108015545643866, 'spinnet_icp_s': 7.906411697156727, 'spinnet_total_s': 73.636643900536, 'spinnet_ransac_fitness': 0.24853515625, 'spinnet_ransac_rmse': 0.005658999159877258, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.001221144650706097, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446507060903, 'spinnet_trimrmse_10mm': 0.00175755084038899, 'spinnet_chamfer': 0.016678767039233537, 'fpfh_T_icp': array([[ 0.95432939,  0.29766853, -0.02547286, -0.04748746],\n",
      "       [-0.29774503,  0.94062514, -0.16300992, -0.93248243],\n",
      "       [-0.02456251,  0.16314958,  0.98629554, -0.0411525 ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.9543294 ,  0.2976685 , -0.02547289, -0.0474876 ],\n",
      "       [-0.297745  ,  0.94062515, -0.16300995, -0.93248255],\n",
      "       [-0.02456249,  0.16314962,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 4096, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 4096, 'mov_kp_n': 4096, 'fpfh_feat_s': 0.41130443289875984, 'fpfh_ransac_s': 0.2936788108199835, 'fpfh_icp_s': 4.801119570620358, 'fpfh_total_s': 5.506102814339101, 'fpfh_ransac_fitness': 0.371826171875, 'fpfh_ransac_rmse': 0.005232535045834024, 'fpfh_icp_fitness': 0.7907028524342994, 'fpfh_icp_rmse': 0.0012211510550166479, 'fpfh_cov_5mm': 0.7907028524342994, 'fpfh_cov_10mm': 0.816550079769982, 'fpfh_trimrmse_5mm': 0.0012211510550166448, 'fpfh_trimrmse_10mm': 0.0017576086860258645, 'fpfh_chamfer': 0.016678690420391665, 'spinnet_ref_feat_s': 32.516887336969376, 'spinnet_mov_feat_s': 32.318078285083175, 'spinnet_feat_s': 64.83496562205255, 'spinnet_ransac_s': 0.7681319061666727, 'spinnet_icp_s': 7.362358796410263, 'spinnet_total_s': 72.96545632462949, 'spinnet_ransac_fitness': 0.234375, 'spinnet_ransac_rmse': 0.005679954214831482, 'spinnet_icp_fitness': 0.7907016836433551, 'spinnet_icp_rmse': 0.0012211375238373936, 'spinnet_cov_5mm': 0.7907016836433551, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211375238373955, 'spinnet_trimrmse_10mm': 0.0017575505841905166, 'spinnet_chamfer': 0.016678762855657094, 'fpfh_T_icp': array([[ 0.95432956,  0.29766786, -0.02547433, -0.04749555],\n",
      "       [-0.29774456,  0.94062494, -0.16301196, -0.93249196],\n",
      "       [-0.02456163,  0.16315197,  0.98629517, -0.04115194],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432941,  0.29766846, -0.02547286, -0.04748745],\n",
      "       [-0.29774496,  0.94062516, -0.16300996, -0.93248258],\n",
      "       [-0.02456251,  0.16314962,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 4096, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 4096, 'mov_kp_n': 4096, 'fpfh_feat_s': 0.43068393971771, 'fpfh_ransac_s': 0.29946773033589125, 'fpfh_icp_s': 6.270394193008542, 'fpfh_total_s': 7.000545863062143, 'fpfh_ransac_fitness': 0.36376953125, 'fpfh_ransac_rmse': 0.0054166489920003495, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446507554152, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446507554198, 'fpfh_trimrmse_10mm': 0.0017575508097828292, 'fpfh_chamfer': 0.016678766766560438, 'spinnet_ref_feat_s': 32.350975973531604, 'spinnet_mov_feat_s': 32.39022611454129, 'spinnet_feat_s': 64.7412020880729, 'spinnet_ransac_s': 0.751487129367888, 'spinnet_icp_s': 7.471270566806197, 'spinnet_total_s': 72.96395978424698, 'spinnet_ransac_fitness': 0.215576171875, 'spinnet_ransac_rmse': 0.005637860532748156, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446553141534, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446553141404, 'spinnet_trimrmse_10mm': 0.0017575510281883095, 'spinnet_chamfer': 0.016678768449703014, 'fpfh_T_icp': array([[ 0.9543294 ,  0.29766849, -0.02547289, -0.04748761],\n",
      "       [-0.297745  ,  0.94062515, -0.16300995, -0.93248254],\n",
      "       [-0.02456248,  0.16314962,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432939,  0.29766852, -0.02547288, -0.04748758],\n",
      "       [-0.29774502,  0.94062514, -0.16300995, -0.93248255],\n",
      "       [-0.0245625 ,  0.16314961,  0.98629554, -0.04115252],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 8192, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 8192, 'mov_kp_n': 8192, 'fpfh_feat_s': 0.4366155155003071, 'fpfh_ransac_s': 0.6816949788480997, 'fpfh_icp_s': 5.8235901314765215, 'fpfh_total_s': 6.941900625824928, 'fpfh_ransac_fitness': 0.5645751953125, 'fpfh_ransac_rmse': 0.004912940973449148, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446545224729, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446545224729, 'fpfh_trimrmse_10mm': 0.0017575508856897066, 'fpfh_chamfer': 0.016678765230645303, 'spinnet_ref_feat_s': 67.28599068708718, 'spinnet_mov_feat_s': 63.97926693595946, 'spinnet_feat_s': 131.26525762304664, 'spinnet_ransac_s': 2.57414420414716, 'spinnet_icp_s': 6.528174760751426, 'spinnet_total_s': 140.36757658794522, 'spinnet_ransac_fitness': 0.342529296875, 'spinnet_ransac_rmse': 0.005534834245843476, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446540268283, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446540268283, 'spinnet_trimrmse_10mm': 0.0017575510383412735, 'spinnet_chamfer': 0.016678768468429524, 'fpfh_T_icp': array([[ 0.95432939,  0.29766851, -0.02547285, -0.04748739],\n",
      "       [-0.29774501,  0.94062514, -0.16300998, -0.93248266],\n",
      "       [-0.02456254,  0.16314962,  0.98629553, -0.04115258],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432939,  0.29766852, -0.02547288, -0.04748756],\n",
      "       [-0.29774503,  0.94062514, -0.16300995, -0.93248254],\n",
      "       [-0.0245625 ,  0.16314961,  0.98629554, -0.04115252],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 8192, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 8192, 'mov_kp_n': 8192, 'fpfh_feat_s': 0.4031024118885398, 'fpfh_ransac_s': 0.785849941894412, 'fpfh_icp_s': 6.882906200364232, 'fpfh_total_s': 8.071858554147184, 'fpfh_ransac_fitness': 0.57763671875, 'fpfh_ransac_rmse': 0.004859899499454304, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.001221144654333737, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.001221144654333737, 'fpfh_trimrmse_10mm': 0.001757550800856735, 'fpfh_chamfer': 0.016678765773471663, 'spinnet_ref_feat_s': 65.31112922728062, 'spinnet_mov_feat_s': 63.84685107227415, 'spinnet_feat_s': 129.15798029955477, 'spinnet_ransac_s': 2.623542451299727, 'spinnet_icp_s': 7.837567476555705, 'spinnet_total_s': 139.6190902274102, 'spinnet_ransac_fitness': 0.4093017578125, 'spinnet_ransac_rmse': 0.005472007774865197, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446544050408, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446544050414, 'spinnet_trimrmse_10mm': 0.001757551019381279, 'spinnet_chamfer': 0.016678768339921945, 'fpfh_T_icp': array([[ 0.95432941,  0.29766846, -0.02547284, -0.04748738],\n",
      "       [-0.29774496,  0.94062516, -0.16300996, -0.93248254],\n",
      "       [-0.02456253,  0.16314961,  0.98629554, -0.04115257],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432939,  0.29766852, -0.02547288, -0.04748755],\n",
      "       [-0.29774502,  0.94062514, -0.16300995, -0.93248253],\n",
      "       [-0.0245625 ,  0.16314961,  0.98629554, -0.04115252],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 8192, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 8192, 'mov_kp_n': 8192, 'fpfh_feat_s': 0.3742140447720885, 'fpfh_ransac_s': 0.6880562156438828, 'fpfh_icp_s': 5.362170129083097, 'fpfh_total_s': 6.424440389499068, 'fpfh_ransac_fitness': 0.5628662109375, 'fpfh_ransac_rmse': 0.004978807013610868, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.001221144549426316, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165483265835656, 'fpfh_trimrmse_5mm': 0.0012211445494263178, 'fpfh_trimrmse_10mm': 0.0017575708134674902, 'fpfh_chamfer': 0.016678756375791602, 'spinnet_ref_feat_s': 64.85619815811515, 'spinnet_mov_feat_s': 64.54615326784551, 'spinnet_feat_s': 129.40235142596066, 'spinnet_ransac_s': 2.5456203930079937, 'spinnet_icp_s': 6.09383012726903, 'spinnet_total_s': 138.04180194623768, 'spinnet_ransac_fitness': 0.337646484375, 'spinnet_ransac_rmse': 0.005385505605802088, 'spinnet_icp_fitness': 0.7907028524342994, 'spinnet_icp_rmse': 0.0012211516935522566, 'spinnet_cov_5mm': 0.7907028524342994, 'spinnet_cov_10mm': 0.8165483265835656, 'spinnet_trimrmse_5mm': 0.0012211516935522525, 'spinnet_trimrmse_10mm': 0.0017575732733408427, 'spinnet_chamfer': 0.016678753743812405, 'fpfh_T_icp': array([[ 0.95432931,  0.29766879, -0.02547273, -0.04748677],\n",
      "       [-0.29774525,  0.94062503, -0.16301017, -0.9324839 ],\n",
      "       [-0.02456276,  0.16314977,  0.98629551, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.9543293 ,  0.29766889, -0.0254721 , -0.04748363],\n",
      "       [-0.29774525,  0.94062502, -0.16301022, -0.93248424],\n",
      "       [-0.02456338,  0.16314963,  0.98629551, -0.04115279],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 16384, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 16384, 'mov_kp_n': 16384, 'fpfh_feat_s': 0.4121385058388114, 'fpfh_ransac_s': 1.9240387193858624, 'fpfh_icp_s': 6.4352068193256855, 'fpfh_total_s': 8.77138404455036, 'fpfh_ransac_fitness': 0.7279052734375, 'fpfh_ransac_rmse': 0.004289048112044208, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446548232696, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446548232646, 'fpfh_trimrmse_10mm': 0.0017575507988862372, 'fpfh_chamfer': 0.016678765738311365, 'spinnet_ref_feat_s': 103.52941512316465, 'spinnet_mov_feat_s': 97.47935076523572, 'spinnet_feat_s': 201.00876588840038, 'spinnet_ransac_s': 9.221841047517955, 'spinnet_icp_s': 6.373349302448332, 'spinnet_total_s': 216.60395623836666, 'spinnet_ransac_fitness': 0.69598388671875, 'spinnet_ransac_rmse': 0.004653607346344608, 'spinnet_icp_fitness': 0.7907028524342994, 'spinnet_icp_rmse': 0.0012211518181492998, 'spinnet_cov_5mm': 0.7907028524342994, 'spinnet_cov_10mm': 0.8165483265835656, 'spinnet_trimrmse_5mm': 0.001221151818149293, 'spinnet_trimrmse_10mm': 0.00175756987801925, 'spinnet_chamfer': 0.01667874667628952, 'fpfh_T_icp': array([[ 0.95432941,  0.29766846, -0.02547284, -0.04748737],\n",
      "       [-0.29774496,  0.94062516, -0.16300996, -0.93248254],\n",
      "       [-0.02456253,  0.16314961,  0.98629554, -0.04115257],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432929,  0.29766882, -0.0254732 , -0.04748889],\n",
      "       [-0.29774536,  0.94062498, -0.16301024, -0.93248423],\n",
      "       [-0.02456234,  0.16314997,  0.98629548, -0.04115291],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 16384, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 16384, 'mov_kp_n': 16384, 'fpfh_feat_s': 0.409649177454412, 'fpfh_ransac_s': 1.9235556228086352, 'fpfh_icp_s': 4.699116793461144, 'fpfh_total_s': 7.032321593724191, 'fpfh_ransac_fitness': 0.72991943359375, 'fpfh_ransac_rmse': 0.00424883703012445, 'fpfh_icp_fitness': 0.7907016836433551, 'fpfh_icp_rmse': 0.0012211384370608709, 'fpfh_cov_5mm': 0.7907016836433551, 'fpfh_cov_10mm': 0.8165483265835656, 'fpfh_trimrmse_5mm': 0.0012211384370608654, 'fpfh_trimrmse_10mm': 0.0017575838598844467, 'fpfh_chamfer': 0.016678822626397964, 'spinnet_ref_feat_s': 101.40206640120596, 'spinnet_mov_feat_s': 98.17516842950135, 'spinnet_feat_s': 199.5772348307073, 'spinnet_ransac_s': 8.826223758980632, 'spinnet_icp_s': 5.61385662201792, 'spinnet_total_s': 214.01731521170586, 'spinnet_ransac_fitness': 0.6954345703125, 'spinnet_ransac_rmse': 0.004811722441740765, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446543750292, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446543750316, 'spinnet_trimrmse_10mm': 0.001757551002443363, 'spinnet_chamfer': 0.016678768364715754, 'fpfh_T_icp': array([[ 0.95432918,  0.29766926, -0.02547203, -0.04748301],\n",
      "       [-0.29774563,  0.94062504, -0.16300941, -0.93248007],\n",
      "       [-0.02456326,  0.16314882,  0.98629565, -0.04115373],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.9543294 ,  0.2976685 , -0.02547287, -0.04748752],\n",
      "       [-0.297745  ,  0.94062515, -0.16300993, -0.93248246],\n",
      "       [-0.0245625 ,  0.16314959,  0.98629554, -0.04115252],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 16384, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 16384, 'mov_kp_n': 16384, 'fpfh_feat_s': 0.4241210976615548, 'fpfh_ransac_s': 1.9745029201731086, 'fpfh_icp_s': 5.604788018390536, 'fpfh_total_s': 8.0034120362252, 'fpfh_ransac_fitness': 0.7265625, 'fpfh_ransac_rmse': 0.0043111122453171995, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.001221144655617199, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.001221144655617176, 'fpfh_trimrmse_10mm': 0.0017575510200045425, 'fpfh_chamfer': 0.01667876828913997, 'spinnet_ref_feat_s': 99.98078233003616, 'spinnet_mov_feat_s': 98.01427666842937, 'spinnet_feat_s': 197.99505899846554, 'spinnet_ransac_s': 8.87313832435757, 'spinnet_icp_s': 7.034598370082676, 'spinnet_total_s': 213.90279569290578, 'spinnet_ransac_fitness': 0.44964599609375, 'spinnet_ransac_rmse': 0.004928654693123575, 'spinnet_icp_fitness': 0.7907028524342994, 'spinnet_icp_rmse': 0.001221151708762192, 'spinnet_cov_5mm': 0.7907028524342994, 'spinnet_cov_10mm': 0.8165483265835656, 'spinnet_trimrmse_5mm': 0.0012211517087621806, 'spinnet_trimrmse_10mm': 0.0017575743354241696, 'spinnet_chamfer': 0.01667875975956311, 'fpfh_T_icp': array([[ 0.95432939,  0.29766853, -0.02547289, -0.0474876 ],\n",
      "       [-0.29774503,  0.94062514, -0.16300995, -0.93248255],\n",
      "       [-0.02456249,  0.16314961,  0.98629554, -0.04115252],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432933,  0.29766881, -0.02547162, -0.04748146],\n",
      "       [-0.2977451 ,  0.94062508, -0.1630102 , -0.93248399],\n",
      "       [-0.0245638 ,  0.16314946,  0.98629553, -0.04115285],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 32768, 'seed': 0, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 32768, 'mov_kp_n': 32768, 'fpfh_feat_s': 0.41781121119856834, 'fpfh_ransac_s': 6.447644756175578, 'fpfh_icp_s': 6.117947956547141, 'fpfh_total_s': 12.983403923921287, 'fpfh_ransac_fitness': 0.77447509765625, 'fpfh_ransac_rmse': 0.003409130815097381, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211452592967933, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211452592968, 'fpfh_trimrmse_10mm': 0.0017575628659402835, 'fpfh_chamfer': 0.01667877967790551, 'spinnet_ref_feat_s': 199.34606291446835, 'spinnet_mov_feat_s': 195.67892869655043, 'spinnet_feat_s': 395.0249916110188, 'spinnet_ransac_s': 38.7238637059927, 'spinnet_icp_s': 5.693150827661157, 'spinnet_total_s': 439.44200614467263, 'spinnet_ransac_fitness': 0.769989013671875, 'spinnet_ransac_rmse': 0.0037764338772339223, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.001221144663228253, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211446632282483, 'spinnet_trimrmse_10mm': 0.0017575513867996628, 'spinnet_chamfer': 0.016678769729965258, 'fpfh_T_icp': array([[ 0.95432956,  0.29766822, -0.02547009, -0.04747365],\n",
      "       [-0.29774428,  0.94062544, -0.16300957, -0.93248019],\n",
      "       [-0.02456496,  0.16314842,  0.98629567, -0.04115397],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432937,  0.29766858, -0.02547285, -0.04748743],\n",
      "       [-0.29774508,  0.94062513, -0.16300995, -0.93248258],\n",
      "       [-0.02456254,  0.1631496 ,  0.98629554, -0.04115253],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 32768, 'seed': 1, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 32768, 'mov_kp_n': 32768, 'fpfh_feat_s': 0.42758654430508614, 'fpfh_ransac_s': 8.313193707726896, 'fpfh_icp_s': 5.186510903760791, 'fpfh_total_s': 13.927291155792773, 'fpfh_ransac_fitness': 0.774871826171875, 'fpfh_ransac_rmse': 0.0033710091144319347, 'fpfh_icp_fitness': 0.7907028524342994, 'fpfh_icp_rmse': 0.0012211517616139483, 'fpfh_cov_5mm': 0.7907028524342994, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.001221151761613937, 'fpfh_trimrmse_10mm': 0.0017575511845929375, 'fpfh_chamfer': 0.01667877006966003, 'spinnet_ref_feat_s': 200.0206215158105, 'spinnet_mov_feat_s': 196.24220900889486, 'spinnet_feat_s': 396.26283052470535, 'spinnet_ransac_s': 32.28745240904391, 'spinnet_icp_s': 6.562158297747374, 'spinnet_total_s': 435.11244123149663, 'spinnet_ransac_fitness': 0.706939697265625, 'spinnet_ransac_rmse': 0.0042539962994590196, 'spinnet_icp_fitness': 0.7907022680388273, 'spinnet_icp_rmse': 0.0012211446547169974, 'spinnet_cov_5mm': 0.7907022680388273, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.00122114465471699, 'spinnet_trimrmse_10mm': 0.0017575508350408777, 'spinnet_chamfer': 0.016678766083212854, 'fpfh_T_icp': array([[ 0.95432938,  0.29766857, -0.02547289, -0.04748761],\n",
      "       [-0.29774507,  0.94062513, -0.16300995, -0.93248258],\n",
      "       [-0.0245625 ,  0.16314961,  0.98629554, -0.04115248],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432941,  0.29766847, -0.02547285, -0.0474874 ],\n",
      "       [-0.29774497,  0.94062516, -0.16300996, -0.93248255],\n",
      "       [-0.02456252,  0.16314961,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}, {'K': 32768, 'seed': 2, 'voxel_size': 0.005, 'patch_radius': 0.3, 'ref_support_n': 57450, 'mov_support_n': 59565, 'ref_kp_n': 32768, 'mov_kp_n': 32768, 'fpfh_feat_s': 0.4335579574108124, 'fpfh_ransac_s': 7.161445723846555, 'fpfh_icp_s': 5.587787544354796, 'fpfh_total_s': 13.182791225612164, 'fpfh_ransac_fitness': 0.77581787109375, 'fpfh_ransac_rmse': 0.003493250572742589, 'fpfh_icp_fitness': 0.7907022680388273, 'fpfh_icp_rmse': 0.0012211446540562334, 'fpfh_cov_5mm': 0.7907022680388273, 'fpfh_cov_10mm': 0.8165477421880936, 'fpfh_trimrmse_5mm': 0.0012211446540562282, 'fpfh_trimrmse_10mm': 0.0017575508064927713, 'fpfh_chamfer': 0.01667876594978968, 'spinnet_ref_feat_s': 200.32233961950988, 'spinnet_mov_feat_s': 195.74973909649998, 'spinnet_feat_s': 396.07207871600986, 'spinnet_ransac_s': 34.01780852302909, 'spinnet_icp_s': 5.485714923590422, 'spinnet_total_s': 435.57560216262937, 'spinnet_ransac_fitness': 0.746826171875, 'spinnet_ransac_rmse': 0.00417423780241824, 'spinnet_icp_fitness': 0.7907016836433551, 'spinnet_icp_rmse': 0.0012211375467751134, 'spinnet_cov_5mm': 0.7907016836433551, 'spinnet_cov_10mm': 0.8165477421880936, 'spinnet_trimrmse_5mm': 0.0012211375467751078, 'spinnet_trimrmse_10mm': 0.0017575512411828521, 'spinnet_chamfer': 0.016678768513770897, 'fpfh_T_icp': array([[ 0.95432941,  0.29766846, -0.02547285, -0.0474874 ],\n",
      "       [-0.29774496,  0.94062516, -0.16300996, -0.93248253],\n",
      "       [-0.02456252,  0.16314961,  0.98629554, -0.04115256],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]]), 'spinnet_T_icp': array([[ 0.95432945,  0.29766834, -0.02547277, -0.04748699],\n",
      "       [-0.29774484,  0.94062523, -0.1630098 , -0.93248172],\n",
      "       [-0.02456253,  0.16314944,  0.98629557, -0.04115249],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.        ]])}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spinnet_cuda12)",
   "language": "python",
   "name": "spinnet_cuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
